{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c7f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "# randomforest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# adaboost & decisiontree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# catboost\n",
    "from catboost import CatBoostClassifier\n",
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ef929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤시드 고정\n",
    "import random\n",
    "import os\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(seed=42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f78f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"fire_occasion1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2499d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36259 entries, 0 to 36258\n",
      "Data columns (total 23 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   화재시각      36259 non-null  object \n",
      " 1   시도        36259 non-null  object \n",
      " 2   시군구       36259 non-null  object \n",
      " 3   화재유형      36259 non-null  object \n",
      " 4   발화열원(대)   36259 non-null  object \n",
      " 5   발화열원(소)   36259 non-null  object \n",
      " 6   발화요인(대)   36259 non-null  object \n",
      " 7   발화요인(소)   36259 non-null  object \n",
      " 8   최초착화물(대)  36259 non-null  object \n",
      " 9   최초착화물(소)  36259 non-null  object \n",
      " 10  인명피해      36259 non-null  int64  \n",
      " 11  사망        36259 non-null  int64  \n",
      " 12  부상        36259 non-null  int64  \n",
      " 13  재산피해      36259 non-null  int64  \n",
      " 14  장소(대)     36259 non-null  object \n",
      " 15  장소(중)     36259 non-null  object \n",
      " 16  장소(소)     36259 non-null  object \n",
      " 17  부동산       36259 non-null  float64\n",
      " 18  동산        36259 non-null  float64\n",
      " 19  month     36259 non-null  int64  \n",
      " 20  day       36259 non-null  int64  \n",
      " 21  hour      36259 non-null  int64  \n",
      " 22  minute    36259 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(13)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9325672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['재산피해']<=1000,'재산피해']=0\n",
    "df.loc[(df['재산피해']>1000)&\n",
    "       (df['재산피해']<=50000),'재산피해']=1\n",
    "df.loc[df['재산피해']>50000,'재산피해']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2e538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.575885\n",
       "1    0.388455\n",
       "2    0.035660\n",
       "Name: 재산피해, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['재산피해'].value_counts()/len(df['재산피해'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61604322",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa7b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재산피해 = 부동산 + 동산\n",
    "X=df.drop(columns=['화재시각','재산피해', '부동산', '동산'])\n",
    "y=df['재산피해']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f32f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns=['시도', '시군구', '화재유형', '발화열원(대)', '발화열원(소)', '발화요인(대)', '발화요인(소)',\n",
    "                  '최초착화물(대)', '최초착화물(소)', '장소(대)', '장소(중)', '장소(소)']\n",
    "\n",
    "for col in category_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    X[col]=label_encoder.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c72e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시도</th>\n",
       "      <th>시군구</th>\n",
       "      <th>화재유형</th>\n",
       "      <th>발화열원(대)</th>\n",
       "      <th>발화열원(소)</th>\n",
       "      <th>발화요인(대)</th>\n",
       "      <th>발화요인(소)</th>\n",
       "      <th>최초착화물(대)</th>\n",
       "      <th>최초착화물(소)</th>\n",
       "      <th>인명피해</th>\n",
       "      <th>사망</th>\n",
       "      <th>부상</th>\n",
       "      <th>장소(대)</th>\n",
       "      <th>장소(중)</th>\n",
       "      <th>장소(소)</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.117834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.770701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.659236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.568282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.559471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36254</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.925110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.312102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.915254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36255</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.516854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.321656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36256</th>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.088106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.248408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36257</th>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.933921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.382022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.429936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.423729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36258</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.365639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36259 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           시도       시군구  화재유형  발화열원(대)   발화열원(소)   발화요인(대)   발화요인(소)  \\\n",
       "0      0.5000  0.140969   0.0    0.500  0.703704  0.636364  0.687500   \n",
       "1      0.2500  0.114537   0.0    0.750  0.037037  0.636364  0.729167   \n",
       "2      0.2500  0.114537   0.0    0.375  0.481481  0.363636  0.395833   \n",
       "3      0.0625  0.568282   0.0    0.750  0.740741  0.818182  0.833333   \n",
       "4      0.0625  0.559471   0.0    0.750  0.740741  0.818182  0.416667   \n",
       "...       ...       ...   ...      ...       ...       ...       ...   \n",
       "36254  0.0625  0.925110   0.0    0.750  0.740741  0.818182  0.812500   \n",
       "36255  0.8125  0.748899   0.0    0.500  0.185185  0.636364  0.500000   \n",
       "36256  0.7500  0.088106   0.0    0.500  0.000000  0.636364  0.500000   \n",
       "36257  0.1875  0.933921   1.0    0.750  0.037037  0.181818  0.062500   \n",
       "36258  0.4375  0.365639   0.0    0.750  0.037037  0.636364  0.125000   \n",
       "\n",
       "       최초착화물(대)  최초착화물(소)      인명피해    사망        부상     장소(대)     장소(중)  \\\n",
       "0      0.250000  0.078652  0.000000  0.00  0.000000  0.285714  0.122449   \n",
       "1      0.416667  0.865169  0.000000  0.00  0.000000  0.285714  0.122449   \n",
       "2      0.333333  0.292135  0.030303  0.25  0.000000  1.000000  0.693878   \n",
       "3      0.750000  0.629213  0.000000  0.00  0.000000  0.357143  0.653061   \n",
       "4      0.750000  0.629213  0.000000  0.00  0.000000  0.285714  0.346939   \n",
       "...         ...       ...       ...   ...       ...       ...       ...   \n",
       "36254  0.750000  0.629213  0.000000  0.00  0.000000  0.857143  0.306122   \n",
       "36255  0.916667  0.516854  0.000000  0.00  0.000000  0.857143  0.306122   \n",
       "36256  0.833333  0.280899  0.000000  0.00  0.000000  0.857143  0.244898   \n",
       "36257  0.666667  0.382022  0.000000  0.00  0.000000  0.785714  0.734694   \n",
       "36258  0.833333  0.719101  0.030303  0.00  0.030303  0.857143  0.306122   \n",
       "\n",
       "          장소(소)  month  day      hour    minute  \n",
       "0      0.117834    0.0  0.0  0.000000  0.000000  \n",
       "1      0.770701    0.0  0.0  0.000000  0.084746  \n",
       "2      0.659236    0.0  0.0  0.000000  0.101695  \n",
       "3      0.955414    0.0  0.0  0.000000  0.118644  \n",
       "4      0.028662    0.0  0.0  0.000000  0.203390  \n",
       "...         ...    ...  ...       ...       ...  \n",
       "36254  0.312102    1.0  1.0  0.956522  0.915254  \n",
       "36255  0.321656    1.0  1.0  1.000000  0.118644  \n",
       "36256  0.248408    1.0  1.0  1.000000  0.152542  \n",
       "36257  0.429936    1.0  1.0  1.000000  0.423729  \n",
       "36258  0.178344    1.0  1.0  1.000000  0.661017  \n",
       "\n",
       "[36259 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ba5a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7660a",
   "metadata": {},
   "source": [
    "### 2. 결과 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b689339",
   "metadata": {},
   "source": [
    "#### 파라미터 조정 : optuna 사용  \n",
    "  \n",
    "* 1. random forest Accuracy : 약 0.708  (0.7079426365140651)\n",
    "* 2. ada boost Accuracy     : 약 0.704  (0.7042195256480971)\n",
    "* 3. decision tree Accuracy : 약 0.685  (0.6854660783232212)\n",
    "* 4. catboost Accuracy      : 약 0.714  (0.7140099282956426)\n",
    "* 5. MLP Accuracy           : 약 0.693  (0.6934638720353006)  \n",
    "  \n",
    "  \n",
    "* 6.1. stacking Accuracy : random forest + ada boost + MLP, final_estimator = decision tree  \n",
    "     => 약 0.617  (6169332597904027)\n",
    "* 6.2. stacking Accuracy : random forest + ada boost + MLP, final_estimator = logistic regression  \n",
    "     => 약 0.706  (0.706150027578599)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b702b09",
   "metadata": {},
   "source": [
    "### 3. modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19aed08",
   "metadata": {},
   "source": [
    "#### 3.1 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161fb2e2",
   "metadata": {},
   "source": [
    "##### 파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19c4708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "\n",
    "    # 랜덤 포레스트 회귀 모델 생성\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에 대한 평가 지표 계산\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae7939e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 01:35:33,865] A new study created in memory with name: no-name-85c5ff92-f8d7-4f63-b251-cd3de8b03aba\n",
      "[I 2023-11-24 01:35:38,820] Trial 0 finished with value: 0.6959459459459459 and parameters: {'n_estimators': 242, 'max_depth': 8, 'min_samples_split': 9}. Best is trial 0 with value: 0.6959459459459459.\n",
      "[I 2023-11-24 01:35:40,614] Trial 1 finished with value: 0.6752619966905681 and parameters: {'n_estimators': 126, 'max_depth': 5, 'min_samples_split': 20}. Best is trial 0 with value: 0.6959459459459459.\n",
      "[I 2023-11-24 01:35:42,823] Trial 2 finished with value: 0.7000827357970215 and parameters: {'n_estimators': 62, 'max_depth': 16, 'min_samples_split': 6}. Best is trial 2 with value: 0.7000827357970215.\n",
      "[I 2023-11-24 01:35:45,730] Trial 3 finished with value: 0.6937396580253723 and parameters: {'n_estimators': 140, 'max_depth': 8, 'min_samples_split': 9}. Best is trial 2 with value: 0.7000827357970215.\n",
      "[I 2023-11-24 01:35:51,631] Trial 4 finished with value: 0.7015995587424159 and parameters: {'n_estimators': 168, 'max_depth': 19, 'min_samples_split': 14}. Best is trial 4 with value: 0.7015995587424159.\n",
      "[I 2023-11-24 01:35:55,164] Trial 5 finished with value: 0.6989795918367347 and parameters: {'n_estimators': 150, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 4 with value: 0.7015995587424159.\n",
      "[I 2023-11-24 01:36:00,856] Trial 6 finished with value: 0.7032542746828461 and parameters: {'n_estimators': 201, 'max_depth': 12, 'min_samples_split': 19}. Best is trial 6 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 01:36:04,322] Trial 7 finished with value: 0.6621621621621622 and parameters: {'n_estimators': 287, 'max_depth': 4, 'min_samples_split': 3}. Best is trial 6 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 01:36:09,190] Trial 8 finished with value: 0.6984280198565913 and parameters: {'n_estimators': 224, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 6 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 01:36:20,926] Trial 9 finished with value: 0.7050468836183121 and parameters: {'n_estimators': 283, 'max_depth': 18, 'min_samples_split': 2}. Best is trial 9 with value: 0.7050468836183121.\n",
      "[I 2023-11-24 01:36:31,281] Trial 10 finished with value: 0.7036679536679536 and parameters: {'n_estimators': 300, 'max_depth': 16, 'min_samples_split': 14}. Best is trial 9 with value: 0.7050468836183121.\n",
      "[I 2023-11-24 01:36:42,006] Trial 11 finished with value: 0.7042195256480971 and parameters: {'n_estimators': 299, 'max_depth': 17, 'min_samples_split': 14}. Best is trial 9 with value: 0.7050468836183121.\n",
      "[I 2023-11-24 01:36:51,801] Trial 12 finished with value: 0.7047710976282405 and parameters: {'n_estimators': 257, 'max_depth': 20, 'min_samples_split': 14}. Best is trial 9 with value: 0.7050468836183121.\n",
      "[I 2023-11-24 01:37:00,827] Trial 13 finished with value: 0.7062879205736349 and parameters: {'n_estimators': 255, 'max_depth': 20, 'min_samples_split': 17}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:37:08,551] Trial 14 finished with value: 0.7022890237175952 and parameters: {'n_estimators': 259, 'max_depth': 13, 'min_samples_split': 17}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:37:15,814] Trial 15 finished with value: 0.7047710976282405 and parameters: {'n_estimators': 201, 'max_depth': 18, 'min_samples_split': 11}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:37:23,672] Trial 16 finished with value: 0.7033921676778819 and parameters: {'n_estimators': 259, 'max_depth': 14, 'min_samples_split': 5}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:37:27,404] Trial 17 finished with value: 0.7027027027027027 and parameters: {'n_estimators': 102, 'max_depth': 20, 'min_samples_split': 17}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:37:34,447] Trial 18 finished with value: 0.7028405956977386 and parameters: {'n_estimators': 216, 'max_depth': 15, 'min_samples_split': 11}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:37:44,282] Trial 19 finished with value: 0.7042195256480971 and parameters: {'n_estimators': 276, 'max_depth': 18, 'min_samples_split': 17}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:37:54,191] Trial 20 finished with value: 0.7039437396580254 and parameters: {'n_estimators': 235, 'max_depth': 20, 'min_samples_split': 4}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:38:04,084] Trial 21 finished with value: 0.7042195256480971 and parameters: {'n_estimators': 265, 'max_depth': 19, 'min_samples_split': 15}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:38:13,494] Trial 22 finished with value: 0.7049089906232764 and parameters: {'n_estimators': 247, 'max_depth': 20, 'min_samples_split': 12}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:38:20,400] Trial 23 finished with value: 0.7039437396580254 and parameters: {'n_estimators': 192, 'max_depth': 17, 'min_samples_split': 9}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:38:28,747] Trial 24 finished with value: 0.7032542746828461 and parameters: {'n_estimators': 242, 'max_depth': 18, 'min_samples_split': 12}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:38:37,633] Trial 25 finished with value: 0.7047710976282405 and parameters: {'n_estimators': 279, 'max_depth': 15, 'min_samples_split': 12}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:38:46,052] Trial 26 finished with value: 0.700634307777165 and parameters: {'n_estimators': 222, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:38:50,140] Trial 27 finished with value: 0.7009100937672367 and parameters: {'n_estimators': 175, 'max_depth': 11, 'min_samples_split': 16}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:38:57,716] Trial 28 finished with value: 0.7054605626034197 and parameters: {'n_estimators': 241, 'max_depth': 17, 'min_samples_split': 19}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:39:06,289] Trial 29 finished with value: 0.7047710976282405 and parameters: {'n_estimators': 274, 'max_depth': 16, 'min_samples_split': 19}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:39:13,158] Trial 30 finished with value: 0.7027027027027027 and parameters: {'n_estimators': 236, 'max_depth': 14, 'min_samples_split': 20}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:39:21,071] Trial 31 finished with value: 0.7049089906232764 and parameters: {'n_estimators': 248, 'max_depth': 19, 'min_samples_split': 18}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:39:30,767] Trial 32 finished with value: 0.7046332046332047 and parameters: {'n_estimators': 288, 'max_depth': 17, 'min_samples_split': 8}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:39:38,594] Trial 33 finished with value: 0.7018753447324876 and parameters: {'n_estimators': 245, 'max_depth': 18, 'min_samples_split': 19}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:39:41,670] Trial 34 finished with value: 0.6858797573083287 and parameters: {'n_estimators': 212, 'max_depth': 6, 'min_samples_split': 16}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:39:51,230] Trial 35 finished with value: 0.7038058466629895 and parameters: {'n_estimators': 270, 'max_depth': 19, 'min_samples_split': 10}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:39:56,931] Trial 36 finished with value: 0.7062879205736349 and parameters: {'n_estimators': 179, 'max_depth': 17, 'min_samples_split': 20}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:00,274] Trial 37 finished with value: 0.7036679536679536 and parameters: {'n_estimators': 109, 'max_depth': 15, 'min_samples_split': 18}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:05,857] Trial 38 finished with value: 0.7040816326530612 and parameters: {'n_estimators': 176, 'max_depth': 16, 'min_samples_split': 20}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:09,791] Trial 39 finished with value: 0.7011858797573083 and parameters: {'n_estimators': 144, 'max_depth': 12, 'min_samples_split': 20}. Best is trial 13 with value: 0.7062879205736349.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 01:40:11,429] Trial 40 finished with value: 0.7013237727523441 and parameters: {'n_estimators': 69, 'max_depth': 10, 'min_samples_split': 18}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:18,778] Trial 41 finished with value: 0.7049089906232764 and parameters: {'n_estimators': 231, 'max_depth': 17, 'min_samples_split': 19}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:25,260] Trial 42 finished with value: 0.7011858797573083 and parameters: {'n_estimators': 189, 'max_depth': 19, 'min_samples_split': 16}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:30,827] Trial 43 finished with value: 0.7017374517374517 and parameters: {'n_estimators': 158, 'max_depth': 18, 'min_samples_split': 13}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:35,129] Trial 44 finished with value: 0.7054605626034197 and parameters: {'n_estimators': 126, 'max_depth': 20, 'min_samples_split': 15}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:39,460] Trial 45 finished with value: 0.7058742415885273 and parameters: {'n_estimators': 130, 'max_depth': 19, 'min_samples_split': 15}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:43,807] Trial 46 finished with value: 0.7050468836183121 and parameters: {'n_estimators': 128, 'max_depth': 19, 'min_samples_split': 15}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:45,397] Trial 47 finished with value: 0.6919470490899062 and parameters: {'n_estimators': 93, 'max_depth': 7, 'min_samples_split': 15}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:49,326] Trial 48 finished with value: 0.7020132377275234 and parameters: {'n_estimators': 127, 'max_depth': 17, 'min_samples_split': 18}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:51,909] Trial 49 finished with value: 0.7036679536679536 and parameters: {'n_estimators': 75, 'max_depth': 20, 'min_samples_split': 16}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:53,377] Trial 50 finished with value: 0.641753998896856 and parameters: {'n_estimators': 159, 'max_depth': 3, 'min_samples_split': 17}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:40:56,822] Trial 51 finished with value: 0.7039437396580254 and parameters: {'n_estimators': 106, 'max_depth': 18, 'min_samples_split': 19}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:41:01,235] Trial 52 finished with value: 0.7018753447324876 and parameters: {'n_estimators': 114, 'max_depth': 19, 'min_samples_split': 2}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:41:05,602] Trial 53 finished with value: 0.7013237727523441 and parameters: {'n_estimators': 139, 'max_depth': 16, 'min_samples_split': 14}. Best is trial 13 with value: 0.7062879205736349.\n",
      "[I 2023-11-24 01:41:09,632] Trial 54 finished with value: 0.7075289575289575 and parameters: {'n_estimators': 118, 'max_depth': 19, 'min_samples_split': 13}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:13,756] Trial 55 finished with value: 0.7049089906232764 and parameters: {'n_estimators': 116, 'max_depth': 20, 'min_samples_split': 13}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:17,159] Trial 56 finished with value: 0.7028405956977386 and parameters: {'n_estimators': 94, 'max_depth': 18, 'min_samples_split': 13}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:20,307] Trial 57 finished with value: 0.7029784886927745 and parameters: {'n_estimators': 85, 'max_depth': 19, 'min_samples_split': 15}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:24,643] Trial 58 finished with value: 0.7047710976282405 and parameters: {'n_estimators': 135, 'max_depth': 17, 'min_samples_split': 17}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:28,936] Trial 59 finished with value: 0.706150027578599 and parameters: {'n_estimators': 151, 'max_depth': 14, 'min_samples_split': 18}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:33,162] Trial 60 finished with value: 0.7027027027027027 and parameters: {'n_estimators': 154, 'max_depth': 14, 'min_samples_split': 19}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:37,768] Trial 61 finished with value: 0.7017374517374517 and parameters: {'n_estimators': 167, 'max_depth': 13, 'min_samples_split': 18}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:39,241] Trial 62 finished with value: 0.7017374517374517 and parameters: {'n_estimators': 50, 'max_depth': 16, 'min_samples_split': 20}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:43,256] Trial 63 finished with value: 0.7025648097076669 and parameters: {'n_estimators': 121, 'max_depth': 19, 'min_samples_split': 16}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:48,424] Trial 64 finished with value: 0.7027027027027027 and parameters: {'n_estimators': 146, 'max_depth': 20, 'min_samples_split': 14}. Best is trial 54 with value: 0.7075289575289575.\n",
      "[I 2023-11-24 01:41:52,997] Trial 65 finished with value: 0.7079426365140651 and parameters: {'n_estimators': 133, 'max_depth': 20, 'min_samples_split': 17}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:41:57,540] Trial 66 finished with value: 0.7036679536679536 and parameters: {'n_estimators': 133, 'max_depth': 18, 'min_samples_split': 17}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:03,016] Trial 67 finished with value: 0.7038058466629895 and parameters: {'n_estimators': 168, 'max_depth': 17, 'min_samples_split': 17}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:08,639] Trial 68 finished with value: 0.705184776613348 and parameters: {'n_estimators': 186, 'max_depth': 15, 'min_samples_split': 18}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:14,351] Trial 69 finished with value: 0.7025648097076669 and parameters: {'n_estimators': 210, 'max_depth': 13, 'min_samples_split': 19}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:19,078] Trial 70 finished with value: 0.7032542746828461 and parameters: {'n_estimators': 149, 'max_depth': 19, 'min_samples_split': 18}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:23,133] Trial 71 finished with value: 0.7038058466629895 and parameters: {'n_estimators': 120, 'max_depth': 20, 'min_samples_split': 15}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:27,371] Trial 72 finished with value: 0.7042195256480971 and parameters: {'n_estimators': 129, 'max_depth': 20, 'min_samples_split': 20}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:32,161] Trial 73 finished with value: 0.7031163816878102 and parameters: {'n_estimators': 139, 'max_depth': 18, 'min_samples_split': 16}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:35,507] Trial 74 finished with value: 0.7042195256480971 and parameters: {'n_estimators': 99, 'max_depth': 20, 'min_samples_split': 14}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:44,267] Trial 75 finished with value: 0.706150027578599 and parameters: {'n_estimators': 256, 'max_depth': 19, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:42:53,618] Trial 76 finished with value: 0.7055984555984556 and parameters: {'n_estimators': 257, 'max_depth': 18, 'min_samples_split': 12}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:43:02,785] Trial 77 finished with value: 0.7033921676778819 and parameters: {'n_estimators': 259, 'max_depth': 19, 'min_samples_split': 10}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:43:12,755] Trial 78 finished with value: 0.7039437396580254 and parameters: {'n_estimators': 288, 'max_depth': 18, 'min_samples_split': 11}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:43:22,350] Trial 79 finished with value: 0.7071152785438499 and parameters: {'n_estimators': 266, 'max_depth': 19, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 01:43:31,185] Trial 80 finished with value: 0.7072531715388858 and parameters: {'n_estimators': 252, 'max_depth': 19, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:43:39,892] Trial 81 finished with value: 0.7073910645339216 and parameters: {'n_estimators': 253, 'max_depth': 19, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:43:48,512] Trial 82 finished with value: 0.7073910645339216 and parameters: {'n_estimators': 253, 'max_depth': 19, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:43:57,297] Trial 83 finished with value: 0.7049089906232764 and parameters: {'n_estimators': 252, 'max_depth': 20, 'min_samples_split': 12}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:44:05,396] Trial 84 finished with value: 0.7042195256480971 and parameters: {'n_estimators': 234, 'max_depth': 19, 'min_samples_split': 11}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:44:14,831] Trial 85 finished with value: 0.7047710976282405 and parameters: {'n_estimators': 267, 'max_depth': 20, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:44:24,016] Trial 86 finished with value: 0.7039437396580254 and parameters: {'n_estimators': 278, 'max_depth': 17, 'min_samples_split': 10}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:44:29,658] Trial 87 finished with value: 0.6991174848317705 and parameters: {'n_estimators': 222, 'max_depth': 11, 'min_samples_split': 12}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:44:39,874] Trial 88 finished with value: 0.7054605626034197 and parameters: {'n_estimators': 298, 'max_depth': 19, 'min_samples_split': 14}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:44:47,636] Trial 89 finished with value: 0.7040816326530612 and parameters: {'n_estimators': 227, 'max_depth': 18, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:44:52,872] Trial 90 finished with value: 0.6970490899062327 and parameters: {'n_estimators': 263, 'max_depth': 9, 'min_samples_split': 11}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:45:01,697] Trial 91 finished with value: 0.7027027027027027 and parameters: {'n_estimators': 252, 'max_depth': 19, 'min_samples_split': 12}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:45:10,039] Trial 92 finished with value: 0.7058742415885273 and parameters: {'n_estimators': 240, 'max_depth': 20, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:45:19,418] Trial 93 finished with value: 0.7067015995587425 and parameters: {'n_estimators': 272, 'max_depth': 19, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:45:28,903] Trial 94 finished with value: 0.7057363485934914 and parameters: {'n_estimators': 272, 'max_depth': 18, 'min_samples_split': 12}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:45:38,276] Trial 95 finished with value: 0.7054605626034197 and parameters: {'n_estimators': 285, 'max_depth': 19, 'min_samples_split': 14}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:45:47,015] Trial 96 finished with value: 0.7053226696083839 and parameters: {'n_estimators': 250, 'max_depth': 20, 'min_samples_split': 13}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:45:57,418] Trial 97 finished with value: 0.7047710976282405 and parameters: {'n_estimators': 295, 'max_depth': 19, 'min_samples_split': 15}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:46:05,800] Trial 98 finished with value: 0.7047710976282405 and parameters: {'n_estimators': 243, 'max_depth': 16, 'min_samples_split': 14}. Best is trial 65 with value: 0.7079426365140651.\n",
      "[I 2023-11-24 01:46:14,855] Trial 99 finished with value: 0.7022890237175952 and parameters: {'n_estimators': 264, 'max_depth': 18, 'min_samples_split': 6}. Best is trial 65 with value: 0.7079426365140651.\n"
     ]
    }
   ],
   "source": [
    "# Optuna로 하이퍼파라미터 최적화 수행\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92ce6956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 133, 'max_depth': 20, 'min_samples_split': 17}\n",
      "Best Accuracy: 0.7079426365140651\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터 및 결과 출력\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1ce01",
   "metadata": {},
   "source": [
    "#### 3.2 AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c5179",
   "metadata": {},
   "source": [
    "##### 파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c415b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.1, 1.0)\n",
    "\n",
    "    # 랜덤 포레스트 회귀 모델 생성\n",
    "    base_classifier = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    model = AdaBoostClassifier(\n",
    "        base_classifier,\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에 대한 평가 지표 계산\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eef093ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 01:48:54,637] A new study created in memory with name: no-name-ccd7340f-9d2b-4fd8-a3e2-22fbbe143a48\n",
      "[I 2023-11-24 01:49:12,523] Trial 0 finished with value: 0.676365140650855 and parameters: {'n_estimators': 72, 'max_depth': 20, 'learning_rate': 0.8270315968295711}. Best is trial 0 with value: 0.676365140650855.\n",
      "[I 2023-11-24 01:49:41,254] Trial 1 finished with value: 0.673469387755102 and parameters: {'n_estimators': 155, 'max_depth': 12, 'learning_rate': 0.8581983092701817}. Best is trial 0 with value: 0.676365140650855.\n",
      "[I 2023-11-24 01:50:04,687] Trial 2 finished with value: 0.6755377826806398 and parameters: {'n_estimators': 111, 'max_depth': 15, 'learning_rate': 0.7033785024234952}. Best is trial 0 with value: 0.676365140650855.\n",
      "[I 2023-11-24 01:50:38,983] Trial 3 finished with value: 0.6773303916161059 and parameters: {'n_estimators': 180, 'max_depth': 13, 'learning_rate': 0.39405569268043683}. Best is trial 3 with value: 0.6773303916161059.\n",
      "[I 2023-11-24 01:51:07,553] Trial 4 finished with value: 0.6594043022614451 and parameters: {'n_estimators': 198, 'max_depth': 10, 'learning_rate': 0.9324261954323955}. Best is trial 3 with value: 0.6773303916161059.\n",
      "[I 2023-11-24 01:51:17,160] Trial 5 finished with value: 0.6960838389409818 and parameters: {'n_estimators': 192, 'max_depth': 3, 'learning_rate': 0.29506918187399644}. Best is trial 5 with value: 0.6960838389409818.\n",
      "[I 2023-11-24 01:51:59,583] Trial 6 finished with value: 0.6784335355763927 and parameters: {'n_estimators': 190, 'max_depth': 17, 'learning_rate': 0.12087803932590033}. Best is trial 5 with value: 0.6960838389409818.\n",
      "[I 2023-11-24 01:52:26,497] Trial 7 finished with value: 0.674434638720353 and parameters: {'n_estimators': 135, 'max_depth': 14, 'learning_rate': 0.7017824470252666}. Best is trial 5 with value: 0.6960838389409818.\n",
      "[I 2023-11-24 01:52:36,150] Trial 8 finished with value: 0.6369277440706013 and parameters: {'n_estimators': 112, 'max_depth': 6, 'learning_rate': 0.42634850372305755}. Best is trial 5 with value: 0.6960838389409818.\n",
      "[I 2023-11-24 01:52:46,285] Trial 9 finished with value: 0.660507446221732 and parameters: {'n_estimators': 64, 'max_depth': 11, 'learning_rate': 0.251638322529942}. Best is trial 5 with value: 0.6960838389409818.\n",
      "[I 2023-11-24 01:52:54,354] Trial 10 finished with value: 0.6955322669608384 and parameters: {'n_estimators': 159, 'max_depth': 3, 'learning_rate': 0.47945658993039186}. Best is trial 5 with value: 0.6960838389409818.\n",
      "[I 2023-11-24 01:53:02,677] Trial 11 finished with value: 0.6976006618863761 and parameters: {'n_estimators': 160, 'max_depth': 3, 'learning_rate': 0.5076080866117874}. Best is trial 11 with value: 0.6976006618863761.\n",
      "[I 2023-11-24 01:53:10,607] Trial 12 finished with value: 0.7010479867622724 and parameters: {'n_estimators': 161, 'max_depth': 3, 'learning_rate': 0.2990286890188985}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:53:26,857] Trial 13 finished with value: 0.6133480419194705 and parameters: {'n_estimators': 156, 'max_depth': 7, 'learning_rate': 0.5731160838582597}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:53:39,998] Trial 14 finished with value: 0.6161059018201875 and parameters: {'n_estimators': 134, 'max_depth': 7, 'learning_rate': 0.5763380260519714}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:53:52,609] Trial 15 finished with value: 0.673469387755102 and parameters: {'n_estimators': 168, 'max_depth': 5, 'learning_rate': 0.31563316360724286}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:54:10,367] Trial 16 finished with value: 0.6479591836734694 and parameters: {'n_estimators': 141, 'max_depth': 9, 'learning_rate': 0.15367790879246124}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:54:15,932] Trial 17 finished with value: 0.689327082184225 and parameters: {'n_estimators': 90, 'max_depth': 4, 'learning_rate': 0.3725661115855756}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:54:35,746] Trial 18 finished with value: 0.6432708218422504 and parameters: {'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.49811587163934884}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:54:44,627] Trial 19 finished with value: 0.6872586872586872 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.21994444879966218}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:54:49,212] Trial 20 finished with value: 0.6985659128516272 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.36853174715810105}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:54:53,625] Trial 21 finished with value: 0.7009100937672367 and parameters: {'n_estimators': 92, 'max_depth': 3, 'learning_rate': 0.30511231013471174}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:55:00,452] Trial 22 finished with value: 0.690292333149476 and parameters: {'n_estimators': 94, 'max_depth': 5, 'learning_rate': 0.21152083026147447}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:55:04,824] Trial 23 finished with value: 0.7009100937672367 and parameters: {'n_estimators': 87, 'max_depth': 3, 'learning_rate': 0.3330251162365299}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:55:11,874] Trial 24 finished with value: 0.6691947049089906 and parameters: {'n_estimators': 79, 'max_depth': 6, 'learning_rate': 0.3245805142463668}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:55:17,972] Trial 25 finished with value: 0.6425813568670712 and parameters: {'n_estimators': 54, 'max_depth': 8, 'learning_rate': 0.1791717209567904}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:55:24,379] Trial 26 finished with value: 0.694015444015444 and parameters: {'n_estimators': 103, 'max_depth': 4, 'learning_rate': 0.26513918759783783}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:55:31,143] Trial 27 finished with value: 0.6894649751792609 and parameters: {'n_estimators': 80, 'max_depth': 6, 'learning_rate': 0.14895399497678938}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:55:37,207] Trial 28 finished with value: 0.6998069498069498 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.25086088353964375}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:55:48,739] Trial 29 finished with value: 0.6753998896856039 and parameters: {'n_estimators': 54, 'max_depth': 16, 'learning_rate': 0.11014905377947429}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:55:58,088] Trial 30 finished with value: 0.6359624931053502 and parameters: {'n_estimators': 71, 'max_depth': 9, 'learning_rate': 0.31404364964060305}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:56:21,835] Trial 31 finished with value: 0.6671263099834528 and parameters: {'n_estimators': 99, 'max_depth': 20, 'learning_rate': 0.23145054329228174}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:56:29,471] Trial 32 finished with value: 0.6956701599558742 and parameters: {'n_estimators': 124, 'max_depth': 4, 'learning_rate': 0.2731643236666642}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:56:36,044] Trial 33 finished with value: 0.6978764478764479 and parameters: {'n_estimators': 110, 'max_depth': 4, 'learning_rate': 0.21090831955017342}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:56:40,122] Trial 34 finished with value: 0.6999448428019857 and parameters: {'n_estimators': 79, 'max_depth': 3, 'learning_rate': 0.344857794448354}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:56:44,953] Trial 35 finished with value: 0.6878102592388307 and parameters: {'n_estimators': 65, 'max_depth': 5, 'learning_rate': 0.41967294294602664}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:56:48,683] Trial 36 finished with value: 0.6944291230005516 and parameters: {'n_estimators': 75, 'max_depth': 3, 'learning_rate': 0.35276575534685484}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:56:57,111] Trial 37 finished with value: 0.6282404853833425 and parameters: {'n_estimators': 86, 'max_depth': 7, 'learning_rate': 0.4112971887768629}. Best is trial 12 with value: 0.7010479867622724.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 01:57:22,369] Trial 38 finished with value: 0.666023166023166 and parameters: {'n_estimators': 149, 'max_depth': 12, 'learning_rate': 0.3316753014845071}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:57:48,638] Trial 39 finished with value: 0.6766409266409267 and parameters: {'n_estimators': 113, 'max_depth': 19, 'learning_rate': 0.28932077856207744}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:57:51,810] Trial 40 finished with value: 0.6959459459459459 and parameters: {'n_estimators': 64, 'max_depth': 3, 'learning_rate': 0.4497791377698136}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:57:58,101] Trial 41 finished with value: 0.6973248758963044 and parameters: {'n_estimators': 101, 'max_depth': 4, 'learning_rate': 0.3773442031104808}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:58:04,075] Trial 42 finished with value: 0.686569222283508 and parameters: {'n_estimators': 82, 'max_depth': 5, 'learning_rate': 0.2709066200917827}. Best is trial 12 with value: 0.7010479867622724.\n",
      "[I 2023-11-24 01:58:09,164] Trial 43 finished with value: 0.7032542746828461 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.18478684085484753}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 01:58:18,367] Trial 44 finished with value: 0.7013237727523441 and parameters: {'n_estimators': 187, 'max_depth': 3, 'learning_rate': 0.2033157735860976}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 01:58:34,413] Trial 45 finished with value: 0.6690568119139547 and parameters: {'n_estimators': 187, 'max_depth': 6, 'learning_rate': 0.1774766692240913}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 01:58:43,657] Trial 46 finished with value: 0.7003585217870932 and parameters: {'n_estimators': 183, 'max_depth': 3, 'learning_rate': 0.10705507650836449}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 01:58:55,776] Trial 47 finished with value: 0.7015995587424159 and parameters: {'n_estimators': 194, 'max_depth': 4, 'learning_rate': 0.17433120433433286}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 01:59:34,750] Trial 48 finished with value: 0.6827082184225042 and parameters: {'n_estimators': 195, 'max_depth': 14, 'learning_rate': 0.17950857983588317}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 01:59:49,420] Trial 49 finished with value: 0.6890512961941533 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.15693862007300896}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:00:15,914] Trial 50 finished with value: 0.6720904578047435 and parameters: {'n_estimators': 172, 'max_depth': 11, 'learning_rate': 0.20702636188472975}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:00:26,320] Trial 51 finished with value: 0.6958080529509101 and parameters: {'n_estimators': 167, 'max_depth': 4, 'learning_rate': 0.29721546684585504}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:00:35,223] Trial 52 finished with value: 0.6998069498069498 and parameters: {'n_estimators': 181, 'max_depth': 3, 'learning_rate': 0.1401953396978467}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:00:47,007] Trial 53 finished with value: 0.6978764478764479 and parameters: {'n_estimators': 192, 'max_depth': 4, 'learning_rate': 0.23701735889110873}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:01:03,180] Trial 54 finished with value: 0.6621621621621622 and parameters: {'n_estimators': 177, 'max_depth': 6, 'learning_rate': 0.2912698240117888}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:01:09,971] Trial 55 finished with value: 0.6973248758963044 and parameters: {'n_estimators': 134, 'max_depth': 3, 'learning_rate': 0.19306168224509299}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:01:21,089] Trial 56 finished with value: 0.6984280198565913 and parameters: {'n_estimators': 149, 'max_depth': 5, 'learning_rate': 0.13499717399137656}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:01:27,369] Trial 57 finished with value: 0.7000827357970215 and parameters: {'n_estimators': 94, 'max_depth': 4, 'learning_rate': 0.2511120442333697}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:01:43,175] Trial 58 finished with value: 0.6274131274131274 and parameters: {'n_estimators': 164, 'max_depth': 7, 'learning_rate': 0.22893850584524816}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:01:52,292] Trial 59 finished with value: 0.6993932708218422 and parameters: {'n_estimators': 187, 'max_depth': 3, 'learning_rate': 0.38434209921950113}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:02:00,035] Trial 60 finished with value: 0.7027027027027027 and parameters: {'n_estimators': 108, 'max_depth': 5, 'learning_rate': 0.10611384816721622}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:02:08,373] Trial 61 finished with value: 0.6962217319360177 and parameters: {'n_estimators': 114, 'max_depth': 5, 'learning_rate': 0.10723336694030772}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:02:13,538] Trial 62 finished with value: 0.6995311638168781 and parameters: {'n_estimators': 107, 'max_depth': 3, 'learning_rate': 0.17828310183525775}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:02:19,320] Trial 63 finished with value: 0.7003585217870932 and parameters: {'n_estimators': 94, 'max_depth': 4, 'learning_rate': 0.14776474094356348}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:02:29,717] Trial 64 finished with value: 0.6616105901820187 and parameters: {'n_estimators': 121, 'max_depth': 6, 'learning_rate': 0.24570645858005202}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:02:38,269] Trial 65 finished with value: 0.7013237727523441 and parameters: {'n_estimators': 130, 'max_depth': 4, 'learning_rate': 0.1008748029819054}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:02:47,733] Trial 66 finished with value: 0.696911196911197 and parameters: {'n_estimators': 129, 'max_depth': 5, 'learning_rate': 0.1263195209485562}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:03:03,689] Trial 67 finished with value: 0.6471318257032542 and parameters: {'n_estimators': 141, 'max_depth': 8, 'learning_rate': 0.10081833270752329}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:03:10,560] Trial 68 finished with value: 0.6991174848317705 and parameters: {'n_estimators': 117, 'max_depth': 4, 'learning_rate': 0.20418022524077356}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:03:17,372] Trial 69 finished with value: 0.6991174848317705 and parameters: {'n_estimators': 107, 'max_depth': 4, 'learning_rate': 0.17131906898504934}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:03:30,590] Trial 70 finished with value: 0.6554054054054054 and parameters: {'n_estimators': 149, 'max_depth': 6, 'learning_rate': 0.20397205326678375}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:03:35,154] Trial 71 finished with value: 0.6981522338665196 and parameters: {'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.13048881707629575}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:03:40,200] Trial 72 finished with value: 0.6999448428019857 and parameters: {'n_estimators': 97, 'max_depth': 3, 'learning_rate': 0.15793147778443375}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:03:47,953] Trial 73 finished with value: 0.6788472145615003 and parameters: {'n_estimators': 105, 'max_depth': 5, 'learning_rate': 0.3128656490788064}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:03:53,265] Trial 74 finished with value: 0.6980143408714837 and parameters: {'n_estimators': 85, 'max_depth': 4, 'learning_rate': 0.2696359440707576}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:04:01,034] Trial 75 finished with value: 0.7028405956977386 and parameters: {'n_estimators': 158, 'max_depth': 3, 'learning_rate': 0.2190293698213252}. Best is trial 43 with value: 0.7032542746828461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 02:04:08,634] Trial 76 finished with value: 0.7022890237175952 and parameters: {'n_estimators': 155, 'max_depth': 3, 'learning_rate': 0.22447309598302348}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:04:19,988] Trial 77 finished with value: 0.6897407611693326 and parameters: {'n_estimators': 157, 'max_depth': 5, 'learning_rate': 0.22661764823084513}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:04:28,406] Trial 78 finished with value: 0.7015995587424159 and parameters: {'n_estimators': 162, 'max_depth': 3, 'learning_rate': 0.19188766937493432}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:04:35,131] Trial 79 finished with value: 0.7032542746828461 and parameters: {'n_estimators': 141, 'max_depth': 3, 'learning_rate': 0.1269964273715558}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:04:42,777] Trial 80 finished with value: 0.7009100937672367 and parameters: {'n_estimators': 152, 'max_depth': 3, 'learning_rate': 0.1903020008928947}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:04:51,655] Trial 81 finished with value: 0.6978764478764479 and parameters: {'n_estimators': 141, 'max_depth': 4, 'learning_rate': 0.12170115915103558}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:05:00,793] Trial 82 finished with value: 0.697738554881412 and parameters: {'n_estimators': 144, 'max_depth': 4, 'learning_rate': 0.16061487909996489}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:05:08,894] Trial 83 finished with value: 0.6985659128516272 and parameters: {'n_estimators': 162, 'max_depth': 3, 'learning_rate': 0.10001086214276994}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:05:15,668] Trial 84 finished with value: 0.6981522338665196 and parameters: {'n_estimators': 132, 'max_depth': 3, 'learning_rate': 0.14868914390352453}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:05:23,563] Trial 85 finished with value: 0.698703805846663 and parameters: {'n_estimators': 127, 'max_depth': 4, 'learning_rate': 0.13378705240582345}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:05:36,269] Trial 86 finished with value: 0.6864313292884722 and parameters: {'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.16748113450958504}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:05:45,948] Trial 87 finished with value: 0.6984280198565913 and parameters: {'n_estimators': 154, 'max_depth': 4, 'learning_rate': 0.19085898173846574}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:05:54,206] Trial 88 finished with value: 0.7025648097076669 and parameters: {'n_estimators': 167, 'max_depth': 3, 'learning_rate': 0.22841921943160615}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:06:03,824] Trial 89 finished with value: 0.7007722007722008 and parameters: {'n_estimators': 196, 'max_depth': 3, 'learning_rate': 0.2051219271268576}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:06:25,091] Trial 90 finished with value: 0.6598179812465527 and parameters: {'n_estimators': 145, 'max_depth': 10, 'learning_rate': 0.23028915021684487}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:06:33,952] Trial 91 finished with value: 0.6991174848317705 and parameters: {'n_estimators': 168, 'max_depth': 3, 'learning_rate': 0.1252850492528233}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:06:42,343] Trial 92 finished with value: 0.6967733039161611 and parameters: {'n_estimators': 137, 'max_depth': 4, 'learning_rate': 0.21746446572081563}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:06:51,045] Trial 93 finished with value: 0.6995311638168781 and parameters: {'n_estimators': 166, 'max_depth': 3, 'learning_rate': 0.1731409100061626}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:07:00,206] Trial 94 finished with value: 0.6995311638168781 and parameters: {'n_estimators': 184, 'max_depth': 3, 'learning_rate': 0.25582196275695157}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:07:35,739] Trial 95 finished with value: 0.6733314947600662 and parameters: {'n_estimators': 158, 'max_depth': 17, 'learning_rate': 0.18803205971650963}. Best is trial 43 with value: 0.7032542746828461.\n",
      "[I 2023-11-24 02:07:46,542] Trial 96 finished with value: 0.7042195256480971 and parameters: {'n_estimators': 175, 'max_depth': 4, 'learning_rate': 0.15900320437580656}. Best is trial 96 with value: 0.7042195256480971.\n",
      "[I 2023-11-24 02:07:55,667] Trial 97 finished with value: 0.7004964147821291 and parameters: {'n_estimators': 173, 'max_depth': 3, 'learning_rate': 0.15710904722297453}. Best is trial 96 with value: 0.7042195256480971.\n",
      "[I 2023-11-24 02:08:09,607] Trial 98 finished with value: 0.6793987865416437 and parameters: {'n_estimators': 179, 'max_depth': 5, 'learning_rate': 0.23932438056950844}. Best is trial 96 with value: 0.7042195256480971.\n",
      "[I 2023-11-24 02:08:42,518] Trial 99 finished with value: 0.6773303916161059 and parameters: {'n_estimators': 175, 'max_depth': 13, 'learning_rate': 0.27591295138142863}. Best is trial 96 with value: 0.7042195256480971.\n"
     ]
    }
   ],
   "source": [
    "# Optuna로 하이퍼파라미터 최적화 수행\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b15efbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 175, 'max_depth': 4, 'learning_rate': 0.15900320437580656}\n",
      "Best Accuracy: 0.7042195256480971\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터 및 결과 출력\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e630c50",
   "metadata": {},
   "source": [
    "#### 3.3 decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c62b757",
   "metadata": {},
   "source": [
    "##### 파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "587a7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "\n",
    "    # 랜덤 포레스트 회귀 모델 생성\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에 대한 평가 지표 계산\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "393165ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 02:08:42,626] A new study created in memory with name: no-name-a0d74645-c255-4c8c-80c6-9ea729c00868\n",
      "[I 2023-11-24 02:08:42,745] Trial 0 finished with value: 0.680088251516823 and parameters: {'max_depth': 8, 'min_samples_split': 5}. Best is trial 0 with value: 0.680088251516823.\n",
      "[I 2023-11-24 02:08:42,898] Trial 1 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 13}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:42,997] Trial 2 finished with value: 0.6832597904026475 and parameters: {'max_depth': 7, 'min_samples_split': 3}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:43,094] Trial 3 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:43,331] Trial 4 finished with value: 0.6490623276337562 and parameters: {'max_depth': 15, 'min_samples_split': 8}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:43,434] Trial 5 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 15}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:43,621] Trial 6 finished with value: 0.6467181467181468 and parameters: {'max_depth': 17, 'min_samples_split': 19}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:43,874] Trial 7 finished with value: 0.6500275785990072 and parameters: {'max_depth': 18, 'min_samples_split': 19}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:44,075] Trial 8 finished with value: 0.6312741312741312 and parameters: {'max_depth': 19, 'min_samples_split': 5}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:44,132] Trial 9 finished with value: 0.6349972421400993 and parameters: {'max_depth': 3, 'min_samples_split': 15}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:44,342] Trial 10 finished with value: 0.657611693325979 and parameters: {'max_depth': 14, 'min_samples_split': 11}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:44,513] Trial 11 finished with value: 0.6784335355763927 and parameters: {'max_depth': 11, 'min_samples_split': 14}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:44,585] Trial 12 finished with value: 0.6599558742415885 and parameters: {'max_depth': 5, 'min_samples_split': 12}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:44,735] Trial 13 finished with value: 0.6802261445118588 and parameters: {'max_depth': 11, 'min_samples_split': 20}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:44,840] Trial 14 finished with value: 0.6769167126309984 and parameters: {'max_depth': 6, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:45,038] Trial 15 finished with value: 0.6694704908990623 and parameters: {'max_depth': 12, 'min_samples_split': 10}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:45,148] Trial 16 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 13}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:45,208] Trial 17 finished with value: 0.6497517926089355 and parameters: {'max_depth': 4, 'min_samples_split': 16}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:45,359] Trial 18 finished with value: 0.6685052399338114 and parameters: {'max_depth': 13, 'min_samples_split': 9}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:45,507] Trial 19 finished with value: 0.6825703254274683 and parameters: {'max_depth': 10, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:45,604] Trial 20 finished with value: 0.6832597904026475 and parameters: {'max_depth': 7, 'min_samples_split': 7}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:45,718] Trial 21 finished with value: 0.6802261445118588 and parameters: {'max_depth': 8, 'min_samples_split': 14}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:45,861] Trial 22 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:46,055] Trial 23 finished with value: 0.681880860452289 and parameters: {'max_depth': 10, 'min_samples_split': 12}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:46,186] Trial 24 finished with value: 0.6769167126309984 and parameters: {'max_depth': 6, 'min_samples_split': 15}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:46,337] Trial 25 finished with value: 0.6696083838940982 and parameters: {'max_depth': 12, 'min_samples_split': 18}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:46,519] Trial 26 finished with value: 0.6507170435741865 and parameters: {'max_depth': 15, 'min_samples_split': 15}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:46,684] Trial 27 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 13}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:46,863] Trial 28 finished with value: 0.6821566464423607 and parameters: {'max_depth': 10, 'min_samples_split': 11}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:47,005] Trial 29 finished with value: 0.6803640375068947 and parameters: {'max_depth': 8, 'min_samples_split': 16}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:47,123] Trial 30 finished with value: 0.6832597904026475 and parameters: {'max_depth': 7, 'min_samples_split': 20}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:47,235] Trial 31 finished with value: 0.6849145063430778 and parameters: {'max_depth': 9, 'min_samples_split': 14}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:47,391] Trial 32 finished with value: 0.6803640375068947 and parameters: {'max_depth': 8, 'min_samples_split': 13}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:47,520] Trial 33 finished with value: 0.6767788196359625 and parameters: {'max_depth': 6, 'min_samples_split': 12}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:47,643] Trial 34 finished with value: 0.6825703254274683 and parameters: {'max_depth': 10, 'min_samples_split': 16}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:47,804] Trial 35 finished with value: 0.6694704908990623 and parameters: {'max_depth': 13, 'min_samples_split': 18}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:47,912] Trial 36 finished with value: 0.6833976833976834 and parameters: {'max_depth': 7, 'min_samples_split': 13}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:48,063] Trial 37 finished with value: 0.6850523993381136 and parameters: {'max_depth': 9, 'min_samples_split': 7}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:48,208] Trial 38 finished with value: 0.6785714285714286 and parameters: {'max_depth': 11, 'min_samples_split': 3}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:48,286] Trial 39 finished with value: 0.6599558742415885 and parameters: {'max_depth': 5, 'min_samples_split': 10}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:48,543] Trial 40 finished with value: 0.6457528957528957 and parameters: {'max_depth': 16, 'min_samples_split': 15}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:48,676] Trial 41 finished with value: 0.6850523993381136 and parameters: {'max_depth': 9, 'min_samples_split': 18}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:48,862] Trial 42 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:49,003] Trial 43 finished with value: 0.6802261445118588 and parameters: {'max_depth': 8, 'min_samples_split': 19}. Best is trial 1 with value: 0.6851902923331494.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 02:08:49,139] Trial 44 finished with value: 0.6784335355763927 and parameters: {'max_depth': 11, 'min_samples_split': 14}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:49,404] Trial 45 finished with value: 0.6374793160507446 and parameters: {'max_depth': 20, 'min_samples_split': 16}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:49,577] Trial 46 finished with value: 0.6675399889685604 and parameters: {'max_depth': 13, 'min_samples_split': 11}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:49,725] Trial 47 finished with value: 0.6829840044125759 and parameters: {'max_depth': 10, 'min_samples_split': 19}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:49,891] Trial 48 finished with value: 0.6696083838940982 and parameters: {'max_depth': 12, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:50,031] Trial 49 finished with value: 0.6833976833976834 and parameters: {'max_depth': 7, 'min_samples_split': 13}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:50,114] Trial 50 finished with value: 0.6599558742415885 and parameters: {'max_depth': 5, 'min_samples_split': 14}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:50,227] Trial 51 finished with value: 0.6849145063430778 and parameters: {'max_depth': 9, 'min_samples_split': 12}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:50,360] Trial 52 finished with value: 0.6803640375068947 and parameters: {'max_depth': 8, 'min_samples_split': 13}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:50,495] Trial 53 finished with value: 0.680088251516823 and parameters: {'max_depth': 11, 'min_samples_split': 15}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:50,658] Trial 54 finished with value: 0.6850523993381136 and parameters: {'max_depth': 9, 'min_samples_split': 16}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:50,837] Trial 55 finished with value: 0.6824324324324325 and parameters: {'max_depth': 10, 'min_samples_split': 10}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:50,992] Trial 56 finished with value: 0.6803640375068947 and parameters: {'max_depth': 8, 'min_samples_split': 15}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:51,074] Trial 57 finished with value: 0.6769167126309984 and parameters: {'max_depth': 6, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:51,165] Trial 58 finished with value: 0.6833976833976834 and parameters: {'max_depth': 7, 'min_samples_split': 14}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:51,315] Trial 59 finished with value: 0.6822945394373966 and parameters: {'max_depth': 10, 'min_samples_split': 13}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:51,503] Trial 60 finished with value: 0.6696083838940982 and parameters: {'max_depth': 12, 'min_samples_split': 18}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:51,621] Trial 61 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:51,768] Trial 62 finished with value: 0.6850523993381136 and parameters: {'max_depth': 9, 'min_samples_split': 16}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:51,905] Trial 63 finished with value: 0.6802261445118588 and parameters: {'max_depth': 8, 'min_samples_split': 12}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:52,100] Trial 64 finished with value: 0.6806398234969664 and parameters: {'max_depth': 11, 'min_samples_split': 19}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:52,263] Trial 65 finished with value: 0.6821566464423607 and parameters: {'max_depth': 10, 'min_samples_split': 11}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:52,387] Trial 66 finished with value: 0.6835355763927192 and parameters: {'max_depth': 7, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:52,544] Trial 67 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 15}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:52,676] Trial 68 finished with value: 0.6805019305019305 and parameters: {'max_depth': 8, 'min_samples_split': 18}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:52,820] Trial 69 finished with value: 0.6802261445118588 and parameters: {'max_depth': 11, 'min_samples_split': 20}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:52,893] Trial 70 finished with value: 0.6349972421400993 and parameters: {'max_depth': 3, 'min_samples_split': 14}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:53,023] Trial 71 finished with value: 0.6851902923331494 and parameters: {'max_depth': 9, 'min_samples_split': 17}. Best is trial 1 with value: 0.6851902923331494.\n",
      "[I 2023-11-24 02:08:53,155] Trial 72 finished with value: 0.6854660783232212 and parameters: {'max_depth': 9, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:53,330] Trial 73 finished with value: 0.6827082184225042 and parameters: {'max_depth': 10, 'min_samples_split': 8}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:53,424] Trial 74 finished with value: 0.6766409266409267 and parameters: {'max_depth': 6, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:53,569] Trial 75 finished with value: 0.680088251516823 and parameters: {'max_depth': 8, 'min_samples_split': 5}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:53,682] Trial 76 finished with value: 0.6853281853281853 and parameters: {'max_depth': 9, 'min_samples_split': 2}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:53,833] Trial 77 finished with value: 0.6810535024820739 and parameters: {'max_depth': 10, 'min_samples_split': 2}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:53,925] Trial 78 finished with value: 0.6832597904026475 and parameters: {'max_depth': 7, 'min_samples_split': 2}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:54,094] Trial 79 finished with value: 0.6822945394373966 and parameters: {'max_depth': 10, 'min_samples_split': 3}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:54,304] Trial 80 finished with value: 0.6691947049089906 and parameters: {'max_depth': 12, 'min_samples_split': 2}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:54,492] Trial 81 finished with value: 0.6854660783232212 and parameters: {'max_depth': 9, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:54,660] Trial 82 finished with value: 0.6853281853281853 and parameters: {'max_depth': 9, 'min_samples_split': 3}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:54,792] Trial 83 finished with value: 0.680088251516823 and parameters: {'max_depth': 8, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:54,926] Trial 84 finished with value: 0.6854660783232212 and parameters: {'max_depth': 9, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:55,120] Trial 85 finished with value: 0.6791230005515719 and parameters: {'max_depth': 11, 'min_samples_split': 6}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:55,256] Trial 86 finished with value: 0.6854660783232212 and parameters: {'max_depth': 9, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:55,407] Trial 87 finished with value: 0.6854660783232212 and parameters: {'max_depth': 9, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:55,568] Trial 88 finished with value: 0.6854660783232212 and parameters: {'max_depth': 9, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 02:08:55,704] Trial 89 finished with value: 0.680088251516823 and parameters: {'max_depth': 8, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:55,871] Trial 90 finished with value: 0.681880860452289 and parameters: {'max_depth': 10, 'min_samples_split': 5}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:55,993] Trial 91 finished with value: 0.6853281853281853 and parameters: {'max_depth': 9, 'min_samples_split': 3}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:56,117] Trial 92 finished with value: 0.6853281853281853 and parameters: {'max_depth': 9, 'min_samples_split': 3}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:56,234] Trial 93 finished with value: 0.6853281853281853 and parameters: {'max_depth': 9, 'min_samples_split': 3}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:56,370] Trial 94 finished with value: 0.6849145063430778 and parameters: {'max_depth': 9, 'min_samples_split': 6}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:56,502] Trial 95 finished with value: 0.6822945394373966 and parameters: {'max_depth': 10, 'min_samples_split': 3}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:56,639] Trial 96 finished with value: 0.6832597904026475 and parameters: {'max_depth': 7, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:56,795] Trial 97 finished with value: 0.680088251516823 and parameters: {'max_depth': 8, 'min_samples_split': 5}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:56,947] Trial 98 finished with value: 0.680088251516823 and parameters: {'max_depth': 8, 'min_samples_split': 4}. Best is trial 72 with value: 0.6854660783232212.\n",
      "[I 2023-11-24 02:08:57,067] Trial 99 finished with value: 0.6853281853281853 and parameters: {'max_depth': 9, 'min_samples_split': 3}. Best is trial 72 with value: 0.6854660783232212.\n"
     ]
    }
   ],
   "source": [
    "# Optuna로 하이퍼파라미터 최적화 수행\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "286d680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 9, 'min_samples_split': 4}\n",
      "Best Accuracy: 0.6854660783232212\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터 및 결과 출력\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48d5ad",
   "metadata": {},
   "source": [
    "#### 3.4 CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef62184",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=df.drop(columns=['화재시각','재산피해', '부동산', '동산'])\n",
    "y1=df['재산피해']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ee7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a621170",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns=['시도', '시군구', '화재유형', '발화열원(대)', '발화열원(소)', '발화요인(대)', '발화요인(소)',\n",
    "                  '최초착화물(대)', '최초착화물(소)', '장소(대)', '장소(중)', '장소(소)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd526ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0619164\ttotal: 368ms\tremaining: 3m 3s\n",
      "1:\tlearn: 1.0285197\ttotal: 814ms\tremaining: 3m 22s\n",
      "2:\tlearn: 0.9988969\ttotal: 1.2s\tremaining: 3m 19s\n",
      "3:\tlearn: 0.9719522\ttotal: 1.66s\tremaining: 3m 25s\n",
      "4:\tlearn: 0.9466674\ttotal: 2.09s\tremaining: 3m 26s\n",
      "5:\tlearn: 0.9242239\ttotal: 2.54s\tremaining: 3m 29s\n",
      "6:\tlearn: 0.9033660\ttotal: 2.99s\tremaining: 3m 30s\n",
      "7:\tlearn: 0.8842106\ttotal: 3.37s\tremaining: 3m 27s\n",
      "8:\tlearn: 0.8666160\ttotal: 3.81s\tremaining: 3m 28s\n",
      "9:\tlearn: 0.8508885\ttotal: 4.18s\tremaining: 3m 24s\n",
      "10:\tlearn: 0.8363781\ttotal: 4.65s\tremaining: 3m 26s\n",
      "11:\tlearn: 0.8221994\ttotal: 5.1s\tremaining: 3m 27s\n",
      "12:\tlearn: 0.8089941\ttotal: 5.58s\tremaining: 3m 29s\n",
      "13:\tlearn: 0.7970486\ttotal: 6.03s\tremaining: 3m 29s\n",
      "14:\tlearn: 0.7866376\ttotal: 6.15s\tremaining: 3m 18s\n",
      "15:\tlearn: 0.7762632\ttotal: 6.53s\tremaining: 3m 17s\n",
      "16:\tlearn: 0.7661241\ttotal: 6.98s\tremaining: 3m 18s\n",
      "17:\tlearn: 0.7567558\ttotal: 7.42s\tremaining: 3m 18s\n",
      "18:\tlearn: 0.7483219\ttotal: 7.82s\tremaining: 3m 18s\n",
      "19:\tlearn: 0.7401244\ttotal: 8.27s\tremaining: 3m 18s\n",
      "20:\tlearn: 0.7320739\ttotal: 8.69s\tremaining: 3m 18s\n",
      "21:\tlearn: 0.7250143\ttotal: 9.11s\tremaining: 3m 17s\n",
      "22:\tlearn: 0.7180776\ttotal: 9.52s\tremaining: 3m 17s\n",
      "23:\tlearn: 0.7112344\ttotal: 9.96s\tremaining: 3m 17s\n",
      "24:\tlearn: 0.7051042\ttotal: 10.4s\tremaining: 3m 17s\n",
      "25:\tlearn: 0.6989281\ttotal: 10.8s\tremaining: 3m 17s\n",
      "26:\tlearn: 0.6932583\ttotal: 11.3s\tremaining: 3m 18s\n",
      "27:\tlearn: 0.6880323\ttotal: 11.7s\tremaining: 3m 16s\n",
      "28:\tlearn: 0.6830054\ttotal: 12.1s\tremaining: 3m 16s\n",
      "29:\tlearn: 0.6783849\ttotal: 12.5s\tremaining: 3m 16s\n",
      "30:\tlearn: 0.6737931\ttotal: 13s\tremaining: 3m 16s\n",
      "31:\tlearn: 0.6695536\ttotal: 13.5s\tremaining: 3m 16s\n",
      "32:\tlearn: 0.6657094\ttotal: 13.9s\tremaining: 3m 16s\n",
      "33:\tlearn: 0.6618119\ttotal: 14.3s\tremaining: 3m 16s\n",
      "34:\tlearn: 0.6582639\ttotal: 14.8s\tremaining: 3m 16s\n",
      "35:\tlearn: 0.6550370\ttotal: 15.3s\tremaining: 3m 16s\n",
      "36:\tlearn: 0.6524913\ttotal: 15.3s\tremaining: 3m 11s\n",
      "37:\tlearn: 0.6495712\ttotal: 15.8s\tremaining: 3m 12s\n",
      "38:\tlearn: 0.6466064\ttotal: 16.3s\tremaining: 3m 12s\n",
      "39:\tlearn: 0.6436465\ttotal: 16.8s\tremaining: 3m 13s\n",
      "40:\tlearn: 0.6410417\ttotal: 17.2s\tremaining: 3m 13s\n",
      "41:\tlearn: 0.6384618\ttotal: 17.7s\tremaining: 3m 12s\n",
      "42:\tlearn: 0.6360769\ttotal: 18.1s\tremaining: 3m 12s\n",
      "43:\tlearn: 0.6337439\ttotal: 18.6s\tremaining: 3m 12s\n",
      "44:\tlearn: 0.6315301\ttotal: 19.1s\tremaining: 3m 12s\n",
      "45:\tlearn: 0.6294659\ttotal: 19.6s\tremaining: 3m 13s\n",
      "46:\tlearn: 0.6274985\ttotal: 20s\tremaining: 3m 13s\n",
      "47:\tlearn: 0.6257605\ttotal: 20.5s\tremaining: 3m 13s\n",
      "48:\tlearn: 0.6242204\ttotal: 21s\tremaining: 3m 13s\n",
      "49:\tlearn: 0.6225578\ttotal: 21.4s\tremaining: 3m 12s\n",
      "50:\tlearn: 0.6209263\ttotal: 21.9s\tremaining: 3m 12s\n",
      "51:\tlearn: 0.6190067\ttotal: 22.3s\tremaining: 3m 12s\n",
      "52:\tlearn: 0.6171235\ttotal: 22.8s\tremaining: 3m 12s\n",
      "53:\tlearn: 0.6163957\ttotal: 22.8s\tremaining: 3m 8s\n",
      "54:\tlearn: 0.6149206\ttotal: 23.3s\tremaining: 3m 8s\n",
      "55:\tlearn: 0.6135286\ttotal: 23.8s\tremaining: 3m 8s\n",
      "56:\tlearn: 0.6122897\ttotal: 24.2s\tremaining: 3m 8s\n",
      "57:\tlearn: 0.6110230\ttotal: 24.6s\tremaining: 3m 7s\n",
      "58:\tlearn: 0.6096051\ttotal: 25.1s\tremaining: 3m 7s\n",
      "59:\tlearn: 0.6083528\ttotal: 25.6s\tremaining: 3m 8s\n",
      "60:\tlearn: 0.6073080\ttotal: 26.1s\tremaining: 3m 8s\n",
      "61:\tlearn: 0.6061030\ttotal: 26.6s\tremaining: 3m 7s\n",
      "62:\tlearn: 0.6048973\ttotal: 27s\tremaining: 3m 7s\n",
      "63:\tlearn: 0.6038572\ttotal: 27.5s\tremaining: 3m 7s\n",
      "64:\tlearn: 0.6023851\ttotal: 28s\tremaining: 3m 7s\n",
      "65:\tlearn: 0.6011439\ttotal: 28.5s\tremaining: 3m 7s\n",
      "66:\tlearn: 0.6000395\ttotal: 28.9s\tremaining: 3m 6s\n",
      "67:\tlearn: 0.5990515\ttotal: 29.4s\tremaining: 3m 6s\n",
      "68:\tlearn: 0.5982740\ttotal: 29.8s\tremaining: 3m 6s\n",
      "69:\tlearn: 0.5974163\ttotal: 30.3s\tremaining: 3m 6s\n",
      "70:\tlearn: 0.5964543\ttotal: 30.8s\tremaining: 3m 6s\n",
      "71:\tlearn: 0.5953613\ttotal: 31.2s\tremaining: 3m 5s\n",
      "72:\tlearn: 0.5944887\ttotal: 31.6s\tremaining: 3m 5s\n",
      "73:\tlearn: 0.5936451\ttotal: 32.1s\tremaining: 3m 4s\n",
      "74:\tlearn: 0.5930709\ttotal: 32.5s\tremaining: 3m 4s\n",
      "75:\tlearn: 0.5921816\ttotal: 33s\tremaining: 3m 3s\n",
      "76:\tlearn: 0.5913859\ttotal: 33.4s\tremaining: 3m 3s\n",
      "77:\tlearn: 0.5905936\ttotal: 33.9s\tremaining: 3m 3s\n",
      "78:\tlearn: 0.5898084\ttotal: 34.2s\tremaining: 3m 2s\n",
      "79:\tlearn: 0.5890002\ttotal: 34.7s\tremaining: 3m 2s\n",
      "80:\tlearn: 0.5884151\ttotal: 35.1s\tremaining: 3m 1s\n",
      "81:\tlearn: 0.5878475\ttotal: 35.6s\tremaining: 3m 1s\n",
      "82:\tlearn: 0.5872347\ttotal: 36.1s\tremaining: 3m 1s\n",
      "83:\tlearn: 0.5862335\ttotal: 36.6s\tremaining: 3m 1s\n",
      "84:\tlearn: 0.5854817\ttotal: 37.1s\tremaining: 3m 1s\n",
      "85:\tlearn: 0.5848216\ttotal: 37.6s\tremaining: 3m 1s\n",
      "86:\tlearn: 0.5846123\ttotal: 37.7s\tremaining: 2m 59s\n",
      "87:\tlearn: 0.5839830\ttotal: 38.2s\tremaining: 2m 58s\n",
      "88:\tlearn: 0.5835338\ttotal: 38.7s\tremaining: 2m 58s\n",
      "89:\tlearn: 0.5828987\ttotal: 39.2s\tremaining: 2m 58s\n",
      "90:\tlearn: 0.5823804\ttotal: 39.6s\tremaining: 2m 57s\n",
      "91:\tlearn: 0.5813490\ttotal: 40.1s\tremaining: 2m 57s\n",
      "92:\tlearn: 0.5808562\ttotal: 40.5s\tremaining: 2m 57s\n",
      "93:\tlearn: 0.5803384\ttotal: 40.9s\tremaining: 2m 56s\n",
      "94:\tlearn: 0.5798128\ttotal: 41.4s\tremaining: 2m 56s\n",
      "95:\tlearn: 0.5793090\ttotal: 41.9s\tremaining: 2m 56s\n",
      "96:\tlearn: 0.5788624\ttotal: 42.3s\tremaining: 2m 55s\n",
      "97:\tlearn: 0.5781542\ttotal: 42.8s\tremaining: 2m 55s\n",
      "98:\tlearn: 0.5776909\ttotal: 43.2s\tremaining: 2m 54s\n",
      "99:\tlearn: 0.5771612\ttotal: 43.7s\tremaining: 2m 54s\n",
      "100:\tlearn: 0.5764917\ttotal: 44.2s\tremaining: 2m 54s\n",
      "101:\tlearn: 0.5760806\ttotal: 44.6s\tremaining: 2m 54s\n",
      "102:\tlearn: 0.5758437\ttotal: 45.1s\tremaining: 2m 53s\n",
      "103:\tlearn: 0.5754695\ttotal: 45.6s\tremaining: 2m 53s\n",
      "104:\tlearn: 0.5748873\ttotal: 46s\tremaining: 2m 53s\n",
      "105:\tlearn: 0.5744756\ttotal: 46.4s\tremaining: 2m 52s\n",
      "106:\tlearn: 0.5737957\ttotal: 46.9s\tremaining: 2m 52s\n",
      "107:\tlearn: 0.5733469\ttotal: 47.5s\tremaining: 2m 52s\n",
      "108:\tlearn: 0.5730013\ttotal: 48s\tremaining: 2m 52s\n",
      "109:\tlearn: 0.5724620\ttotal: 48.4s\tremaining: 2m 51s\n",
      "110:\tlearn: 0.5719491\ttotal: 48.9s\tremaining: 2m 51s\n",
      "111:\tlearn: 0.5715212\ttotal: 49.4s\tremaining: 2m 51s\n",
      "112:\tlearn: 0.5711551\ttotal: 50s\tremaining: 2m 51s\n",
      "113:\tlearn: 0.5706908\ttotal: 50.5s\tremaining: 2m 50s\n",
      "114:\tlearn: 0.5702136\ttotal: 50.9s\tremaining: 2m 50s\n",
      "115:\tlearn: 0.5693335\ttotal: 51.4s\tremaining: 2m 50s\n",
      "116:\tlearn: 0.5688658\ttotal: 51.9s\tremaining: 2m 49s\n",
      "117:\tlearn: 0.5684282\ttotal: 52.4s\tremaining: 2m 49s\n",
      "118:\tlearn: 0.5682891\ttotal: 52.9s\tremaining: 2m 49s\n",
      "119:\tlearn: 0.5678838\ttotal: 53.3s\tremaining: 2m 48s\n",
      "120:\tlearn: 0.5672585\ttotal: 53.8s\tremaining: 2m 48s\n",
      "121:\tlearn: 0.5670380\ttotal: 54.2s\tremaining: 2m 48s\n",
      "122:\tlearn: 0.5667599\ttotal: 54.7s\tremaining: 2m 47s\n",
      "123:\tlearn: 0.5662861\ttotal: 55.2s\tremaining: 2m 47s\n",
      "124:\tlearn: 0.5658148\ttotal: 55.6s\tremaining: 2m 46s\n",
      "125:\tlearn: 0.5652709\ttotal: 56.1s\tremaining: 2m 46s\n",
      "126:\tlearn: 0.5649132\ttotal: 56.5s\tremaining: 2m 46s\n",
      "127:\tlearn: 0.5644390\ttotal: 57s\tremaining: 2m 45s\n",
      "128:\tlearn: 0.5640277\ttotal: 57.5s\tremaining: 2m 45s\n",
      "129:\tlearn: 0.5635309\ttotal: 58s\tremaining: 2m 44s\n",
      "130:\tlearn: 0.5630748\ttotal: 58.4s\tremaining: 2m 44s\n",
      "131:\tlearn: 0.5626604\ttotal: 58.8s\tremaining: 2m 43s\n",
      "132:\tlearn: 0.5622703\ttotal: 59.3s\tremaining: 2m 43s\n",
      "133:\tlearn: 0.5617983\ttotal: 59.8s\tremaining: 2m 43s\n",
      "134:\tlearn: 0.5615472\ttotal: 1m\tremaining: 2m 42s\n",
      "135:\tlearn: 0.5612333\ttotal: 1m\tremaining: 2m 42s\n",
      "136:\tlearn: 0.5609477\ttotal: 1m 1s\tremaining: 2m 42s\n",
      "137:\tlearn: 0.5605378\ttotal: 1m 1s\tremaining: 2m 41s\n",
      "138:\tlearn: 0.5599591\ttotal: 1m 2s\tremaining: 2m 41s\n",
      "139:\tlearn: 0.5594605\ttotal: 1m 2s\tremaining: 2m 40s\n",
      "140:\tlearn: 0.5590712\ttotal: 1m 3s\tremaining: 2m 40s\n",
      "141:\tlearn: 0.5587199\ttotal: 1m 3s\tremaining: 2m 40s\n",
      "142:\tlearn: 0.5585598\ttotal: 1m 3s\tremaining: 2m 39s\n",
      "143:\tlearn: 0.5579915\ttotal: 1m 4s\tremaining: 2m 39s\n",
      "144:\tlearn: 0.5577845\ttotal: 1m 4s\tremaining: 2m 38s\n",
      "145:\tlearn: 0.5571804\ttotal: 1m 5s\tremaining: 2m 38s\n",
      "146:\tlearn: 0.5567882\ttotal: 1m 5s\tremaining: 2m 38s\n",
      "147:\tlearn: 0.5561401\ttotal: 1m 6s\tremaining: 2m 37s\n",
      "148:\tlearn: 0.5557579\ttotal: 1m 6s\tremaining: 2m 37s\n",
      "149:\tlearn: 0.5554386\ttotal: 1m 7s\tremaining: 2m 36s\n",
      "150:\tlearn: 0.5553879\ttotal: 1m 7s\tremaining: 2m 35s\n",
      "151:\tlearn: 0.5548794\ttotal: 1m 7s\tremaining: 2m 35s\n",
      "152:\tlearn: 0.5543268\ttotal: 1m 8s\tremaining: 2m 34s\n",
      "153:\tlearn: 0.5539356\ttotal: 1m 8s\tremaining: 2m 34s\n",
      "154:\tlearn: 0.5535433\ttotal: 1m 9s\tremaining: 2m 34s\n",
      "155:\tlearn: 0.5531535\ttotal: 1m 9s\tremaining: 2m 33s\n",
      "156:\tlearn: 0.5528272\ttotal: 1m 10s\tremaining: 2m 33s\n",
      "157:\tlearn: 0.5524576\ttotal: 1m 10s\tremaining: 2m 32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 0.5520709\ttotal: 1m 11s\tremaining: 2m 32s\n",
      "159:\tlearn: 0.5517631\ttotal: 1m 11s\tremaining: 2m 31s\n",
      "160:\tlearn: 0.5510857\ttotal: 1m 11s\tremaining: 2m 31s\n",
      "161:\tlearn: 0.5501309\ttotal: 1m 12s\tremaining: 2m 31s\n",
      "162:\tlearn: 0.5496520\ttotal: 1m 12s\tremaining: 2m 30s\n",
      "163:\tlearn: 0.5494719\ttotal: 1m 13s\tremaining: 2m 30s\n",
      "164:\tlearn: 0.5490134\ttotal: 1m 13s\tremaining: 2m 29s\n",
      "165:\tlearn: 0.5487899\ttotal: 1m 14s\tremaining: 2m 29s\n",
      "166:\tlearn: 0.5484439\ttotal: 1m 14s\tremaining: 2m 29s\n",
      "167:\tlearn: 0.5482071\ttotal: 1m 15s\tremaining: 2m 28s\n",
      "168:\tlearn: 0.5479298\ttotal: 1m 15s\tremaining: 2m 28s\n",
      "169:\tlearn: 0.5476291\ttotal: 1m 16s\tremaining: 2m 27s\n",
      "170:\tlearn: 0.5473862\ttotal: 1m 16s\tremaining: 2m 27s\n",
      "171:\tlearn: 0.5472697\ttotal: 1m 17s\tremaining: 2m 26s\n",
      "172:\tlearn: 0.5471113\ttotal: 1m 17s\tremaining: 2m 26s\n",
      "173:\tlearn: 0.5465982\ttotal: 1m 17s\tremaining: 2m 25s\n",
      "174:\tlearn: 0.5460628\ttotal: 1m 18s\tremaining: 2m 25s\n",
      "175:\tlearn: 0.5453516\ttotal: 1m 18s\tremaining: 2m 25s\n",
      "176:\tlearn: 0.5452237\ttotal: 1m 19s\tremaining: 2m 24s\n",
      "177:\tlearn: 0.5447058\ttotal: 1m 19s\tremaining: 2m 24s\n",
      "178:\tlearn: 0.5444090\ttotal: 1m 20s\tremaining: 2m 23s\n",
      "179:\tlearn: 0.5439945\ttotal: 1m 20s\tremaining: 2m 23s\n",
      "180:\tlearn: 0.5436982\ttotal: 1m 21s\tremaining: 2m 22s\n",
      "181:\tlearn: 0.5434041\ttotal: 1m 21s\tremaining: 2m 22s\n",
      "182:\tlearn: 0.5427095\ttotal: 1m 22s\tremaining: 2m 22s\n",
      "183:\tlearn: 0.5423934\ttotal: 1m 22s\tremaining: 2m 21s\n",
      "184:\tlearn: 0.5421622\ttotal: 1m 23s\tremaining: 2m 21s\n",
      "185:\tlearn: 0.5420058\ttotal: 1m 23s\tremaining: 2m 21s\n",
      "186:\tlearn: 0.5415780\ttotal: 1m 23s\tremaining: 2m 20s\n",
      "187:\tlearn: 0.5413321\ttotal: 1m 24s\tremaining: 2m 20s\n",
      "188:\tlearn: 0.5406598\ttotal: 1m 24s\tremaining: 2m 19s\n",
      "189:\tlearn: 0.5402208\ttotal: 1m 25s\tremaining: 2m 19s\n",
      "190:\tlearn: 0.5400588\ttotal: 1m 25s\tremaining: 2m 18s\n",
      "191:\tlearn: 0.5398555\ttotal: 1m 26s\tremaining: 2m 18s\n",
      "192:\tlearn: 0.5393575\ttotal: 1m 26s\tremaining: 2m 18s\n",
      "193:\tlearn: 0.5389275\ttotal: 1m 27s\tremaining: 2m 17s\n",
      "194:\tlearn: 0.5384015\ttotal: 1m 27s\tremaining: 2m 17s\n",
      "195:\tlearn: 0.5379262\ttotal: 1m 28s\tremaining: 2m 16s\n",
      "196:\tlearn: 0.5376448\ttotal: 1m 28s\tremaining: 2m 16s\n",
      "197:\tlearn: 0.5370403\ttotal: 1m 29s\tremaining: 2m 16s\n",
      "198:\tlearn: 0.5367032\ttotal: 1m 29s\tremaining: 2m 15s\n",
      "199:\tlearn: 0.5358198\ttotal: 1m 30s\tremaining: 2m 15s\n",
      "200:\tlearn: 0.5353114\ttotal: 1m 30s\tremaining: 2m 14s\n",
      "201:\tlearn: 0.5348838\ttotal: 1m 30s\tremaining: 2m 14s\n",
      "202:\tlearn: 0.5343253\ttotal: 1m 31s\tremaining: 2m 13s\n",
      "203:\tlearn: 0.5338059\ttotal: 1m 31s\tremaining: 2m 13s\n",
      "204:\tlearn: 0.5331941\ttotal: 1m 32s\tremaining: 2m 13s\n",
      "205:\tlearn: 0.5327600\ttotal: 1m 32s\tremaining: 2m 12s\n",
      "206:\tlearn: 0.5323462\ttotal: 1m 33s\tremaining: 2m 12s\n",
      "207:\tlearn: 0.5320021\ttotal: 1m 33s\tremaining: 2m 11s\n",
      "208:\tlearn: 0.5317409\ttotal: 1m 34s\tremaining: 2m 11s\n",
      "209:\tlearn: 0.5313153\ttotal: 1m 34s\tremaining: 2m 11s\n",
      "210:\tlearn: 0.5306442\ttotal: 1m 35s\tremaining: 2m 10s\n",
      "211:\tlearn: 0.5301207\ttotal: 1m 35s\tremaining: 2m 10s\n",
      "212:\tlearn: 0.5296622\ttotal: 1m 36s\tremaining: 2m 9s\n",
      "213:\tlearn: 0.5293926\ttotal: 1m 36s\tremaining: 2m 9s\n",
      "214:\tlearn: 0.5286797\ttotal: 1m 37s\tremaining: 2m 8s\n",
      "215:\tlearn: 0.5283202\ttotal: 1m 37s\tremaining: 2m 8s\n",
      "216:\tlearn: 0.5279224\ttotal: 1m 38s\tremaining: 2m 8s\n",
      "217:\tlearn: 0.5273061\ttotal: 1m 38s\tremaining: 2m 7s\n",
      "218:\tlearn: 0.5266382\ttotal: 1m 39s\tremaining: 2m 7s\n",
      "219:\tlearn: 0.5259388\ttotal: 1m 39s\tremaining: 2m 6s\n",
      "220:\tlearn: 0.5254162\ttotal: 1m 40s\tremaining: 2m 6s\n",
      "221:\tlearn: 0.5250086\ttotal: 1m 40s\tremaining: 2m 5s\n",
      "222:\tlearn: 0.5245192\ttotal: 1m 40s\tremaining: 2m 5s\n",
      "223:\tlearn: 0.5243295\ttotal: 1m 41s\tremaining: 2m 4s\n",
      "224:\tlearn: 0.5238330\ttotal: 1m 41s\tremaining: 2m 4s\n",
      "225:\tlearn: 0.5235862\ttotal: 1m 42s\tremaining: 2m 4s\n",
      "226:\tlearn: 0.5232782\ttotal: 1m 42s\tremaining: 2m 3s\n",
      "227:\tlearn: 0.5231090\ttotal: 1m 43s\tremaining: 2m 3s\n",
      "228:\tlearn: 0.5226534\ttotal: 1m 43s\tremaining: 2m 2s\n",
      "229:\tlearn: 0.5219471\ttotal: 1m 44s\tremaining: 2m 2s\n",
      "230:\tlearn: 0.5217013\ttotal: 1m 44s\tremaining: 2m 1s\n",
      "231:\tlearn: 0.5212486\ttotal: 1m 45s\tremaining: 2m 1s\n",
      "232:\tlearn: 0.5205051\ttotal: 1m 45s\tremaining: 2m\n",
      "233:\tlearn: 0.5199444\ttotal: 1m 46s\tremaining: 2m\n",
      "234:\tlearn: 0.5194476\ttotal: 1m 46s\tremaining: 2m\n",
      "235:\tlearn: 0.5190808\ttotal: 1m 46s\tremaining: 1m 59s\n",
      "236:\tlearn: 0.5186309\ttotal: 1m 47s\tremaining: 1m 59s\n",
      "237:\tlearn: 0.5182275\ttotal: 1m 47s\tremaining: 1m 58s\n",
      "238:\tlearn: 0.5174966\ttotal: 1m 48s\tremaining: 1m 58s\n",
      "239:\tlearn: 0.5171031\ttotal: 1m 48s\tremaining: 1m 57s\n",
      "240:\tlearn: 0.5164188\ttotal: 1m 49s\tremaining: 1m 57s\n",
      "241:\tlearn: 0.5158608\ttotal: 1m 49s\tremaining: 1m 56s\n",
      "242:\tlearn: 0.5154566\ttotal: 1m 50s\tremaining: 1m 56s\n",
      "243:\tlearn: 0.5147858\ttotal: 1m 50s\tremaining: 1m 56s\n",
      "244:\tlearn: 0.5145072\ttotal: 1m 51s\tremaining: 1m 55s\n",
      "245:\tlearn: 0.5138861\ttotal: 1m 51s\tremaining: 1m 55s\n",
      "246:\tlearn: 0.5134551\ttotal: 1m 52s\tremaining: 1m 54s\n",
      "247:\tlearn: 0.5129394\ttotal: 1m 52s\tremaining: 1m 54s\n",
      "248:\tlearn: 0.5125630\ttotal: 1m 52s\tremaining: 1m 53s\n",
      "249:\tlearn: 0.5121658\ttotal: 1m 53s\tremaining: 1m 53s\n",
      "250:\tlearn: 0.5116046\ttotal: 1m 53s\tremaining: 1m 53s\n",
      "251:\tlearn: 0.5109582\ttotal: 1m 54s\tremaining: 1m 52s\n",
      "252:\tlearn: 0.5104563\ttotal: 1m 54s\tremaining: 1m 52s\n",
      "253:\tlearn: 0.5096115\ttotal: 1m 55s\tremaining: 1m 51s\n",
      "254:\tlearn: 0.5091113\ttotal: 1m 55s\tremaining: 1m 51s\n",
      "255:\tlearn: 0.5087616\ttotal: 1m 56s\tremaining: 1m 50s\n",
      "256:\tlearn: 0.5084596\ttotal: 1m 56s\tremaining: 1m 50s\n",
      "257:\tlearn: 0.5079091\ttotal: 1m 57s\tremaining: 1m 50s\n",
      "258:\tlearn: 0.5073694\ttotal: 1m 57s\tremaining: 1m 49s\n",
      "259:\tlearn: 0.5070997\ttotal: 1m 58s\tremaining: 1m 49s\n",
      "260:\tlearn: 0.5064433\ttotal: 1m 58s\tremaining: 1m 48s\n",
      "261:\tlearn: 0.5062686\ttotal: 1m 59s\tremaining: 1m 48s\n",
      "262:\tlearn: 0.5057839\ttotal: 1m 59s\tremaining: 1m 47s\n",
      "263:\tlearn: 0.5052369\ttotal: 2m\tremaining: 1m 47s\n",
      "264:\tlearn: 0.5047695\ttotal: 2m\tremaining: 1m 47s\n",
      "265:\tlearn: 0.5043774\ttotal: 2m 1s\tremaining: 1m 46s\n",
      "266:\tlearn: 0.5041978\ttotal: 2m 1s\tremaining: 1m 46s\n",
      "267:\tlearn: 0.5036522\ttotal: 2m 2s\tremaining: 1m 45s\n",
      "268:\tlearn: 0.5032369\ttotal: 2m 2s\tremaining: 1m 45s\n",
      "269:\tlearn: 0.5028374\ttotal: 2m 3s\tremaining: 1m 45s\n",
      "270:\tlearn: 0.5027272\ttotal: 2m 4s\tremaining: 1m 44s\n",
      "271:\tlearn: 0.5024550\ttotal: 2m 4s\tremaining: 1m 44s\n",
      "272:\tlearn: 0.5019795\ttotal: 2m 5s\tremaining: 1m 44s\n",
      "273:\tlearn: 0.5016234\ttotal: 2m 5s\tremaining: 1m 43s\n",
      "274:\tlearn: 0.5011652\ttotal: 2m 6s\tremaining: 1m 43s\n",
      "275:\tlearn: 0.5008016\ttotal: 2m 6s\tremaining: 1m 42s\n",
      "276:\tlearn: 0.5005568\ttotal: 2m 7s\tremaining: 1m 42s\n",
      "277:\tlearn: 0.5000849\ttotal: 2m 7s\tremaining: 1m 41s\n",
      "278:\tlearn: 0.4996869\ttotal: 2m 8s\tremaining: 1m 41s\n",
      "279:\tlearn: 0.4993538\ttotal: 2m 8s\tremaining: 1m 41s\n",
      "280:\tlearn: 0.4990729\ttotal: 2m 9s\tremaining: 1m 40s\n",
      "281:\tlearn: 0.4984108\ttotal: 2m 9s\tremaining: 1m 40s\n",
      "282:\tlearn: 0.4978427\ttotal: 2m 10s\tremaining: 1m 39s\n",
      "283:\tlearn: 0.4974799\ttotal: 2m 10s\tremaining: 1m 39s\n",
      "284:\tlearn: 0.4970314\ttotal: 2m 11s\tremaining: 1m 38s\n",
      "285:\tlearn: 0.4967022\ttotal: 2m 11s\tremaining: 1m 38s\n",
      "286:\tlearn: 0.4963043\ttotal: 2m 12s\tremaining: 1m 38s\n",
      "287:\tlearn: 0.4960216\ttotal: 2m 12s\tremaining: 1m 37s\n",
      "288:\tlearn: 0.4957000\ttotal: 2m 13s\tremaining: 1m 37s\n",
      "289:\tlearn: 0.4949657\ttotal: 2m 13s\tremaining: 1m 36s\n",
      "290:\tlearn: 0.4945921\ttotal: 2m 14s\tremaining: 1m 36s\n",
      "291:\tlearn: 0.4941600\ttotal: 2m 14s\tremaining: 1m 36s\n",
      "292:\tlearn: 0.4938052\ttotal: 2m 15s\tremaining: 1m 35s\n",
      "293:\tlearn: 0.4934041\ttotal: 2m 16s\tremaining: 1m 35s\n",
      "294:\tlearn: 0.4927906\ttotal: 2m 16s\tremaining: 1m 34s\n",
      "295:\tlearn: 0.4923426\ttotal: 2m 17s\tremaining: 1m 34s\n",
      "296:\tlearn: 0.4920899\ttotal: 2m 17s\tremaining: 1m 34s\n",
      "297:\tlearn: 0.4919271\ttotal: 2m 18s\tremaining: 1m 33s\n",
      "298:\tlearn: 0.4914044\ttotal: 2m 18s\tremaining: 1m 33s\n",
      "299:\tlearn: 0.4910995\ttotal: 2m 19s\tremaining: 1m 32s\n",
      "300:\tlearn: 0.4906270\ttotal: 2m 19s\tremaining: 1m 32s\n",
      "301:\tlearn: 0.4901721\ttotal: 2m 19s\tremaining: 1m 31s\n",
      "302:\tlearn: 0.4897427\ttotal: 2m 20s\tremaining: 1m 31s\n",
      "303:\tlearn: 0.4893596\ttotal: 2m 20s\tremaining: 1m 30s\n",
      "304:\tlearn: 0.4890178\ttotal: 2m 21s\tremaining: 1m 30s\n",
      "305:\tlearn: 0.4884631\ttotal: 2m 21s\tremaining: 1m 29s\n",
      "306:\tlearn: 0.4878586\ttotal: 2m 22s\tremaining: 1m 29s\n",
      "307:\tlearn: 0.4874176\ttotal: 2m 22s\tremaining: 1m 29s\n",
      "308:\tlearn: 0.4866413\ttotal: 2m 23s\tremaining: 1m 28s\n",
      "309:\tlearn: 0.4862839\ttotal: 2m 23s\tremaining: 1m 28s\n",
      "310:\tlearn: 0.4855468\ttotal: 2m 24s\tremaining: 1m 27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311:\tlearn: 0.4849735\ttotal: 2m 25s\tremaining: 1m 27s\n",
      "312:\tlearn: 0.4843918\ttotal: 2m 26s\tremaining: 1m 27s\n",
      "313:\tlearn: 0.4839304\ttotal: 2m 26s\tremaining: 1m 26s\n",
      "314:\tlearn: 0.4834927\ttotal: 2m 27s\tremaining: 1m 26s\n",
      "315:\tlearn: 0.4832176\ttotal: 2m 27s\tremaining: 1m 26s\n",
      "316:\tlearn: 0.4827986\ttotal: 2m 28s\tremaining: 1m 25s\n",
      "317:\tlearn: 0.4823716\ttotal: 2m 29s\tremaining: 1m 25s\n",
      "318:\tlearn: 0.4816442\ttotal: 2m 29s\tremaining: 1m 24s\n",
      "319:\tlearn: 0.4811130\ttotal: 2m 30s\tremaining: 1m 24s\n",
      "320:\tlearn: 0.4806089\ttotal: 2m 30s\tremaining: 1m 24s\n",
      "321:\tlearn: 0.4801877\ttotal: 2m 31s\tremaining: 1m 23s\n",
      "322:\tlearn: 0.4798363\ttotal: 2m 31s\tremaining: 1m 23s\n",
      "323:\tlearn: 0.4797082\ttotal: 2m 32s\tremaining: 1m 22s\n",
      "324:\tlearn: 0.4793159\ttotal: 2m 32s\tremaining: 1m 22s\n",
      "325:\tlearn: 0.4790728\ttotal: 2m 33s\tremaining: 1m 21s\n",
      "326:\tlearn: 0.4785490\ttotal: 2m 33s\tremaining: 1m 21s\n",
      "327:\tlearn: 0.4783539\ttotal: 2m 34s\tremaining: 1m 20s\n",
      "328:\tlearn: 0.4778748\ttotal: 2m 34s\tremaining: 1m 20s\n",
      "329:\tlearn: 0.4772932\ttotal: 2m 35s\tremaining: 1m 20s\n",
      "330:\tlearn: 0.4769697\ttotal: 2m 35s\tremaining: 1m 19s\n",
      "331:\tlearn: 0.4766455\ttotal: 2m 36s\tremaining: 1m 19s\n",
      "332:\tlearn: 0.4763288\ttotal: 2m 37s\tremaining: 1m 18s\n",
      "333:\tlearn: 0.4761279\ttotal: 2m 37s\tremaining: 1m 18s\n",
      "334:\tlearn: 0.4755420\ttotal: 2m 38s\tremaining: 1m 18s\n",
      "335:\tlearn: 0.4750000\ttotal: 2m 39s\tremaining: 1m 17s\n",
      "336:\tlearn: 0.4744672\ttotal: 2m 39s\tremaining: 1m 17s\n",
      "337:\tlearn: 0.4740262\ttotal: 2m 40s\tremaining: 1m 16s\n",
      "338:\tlearn: 0.4734080\ttotal: 2m 40s\tremaining: 1m 16s\n",
      "339:\tlearn: 0.4729833\ttotal: 2m 41s\tremaining: 1m 15s\n",
      "340:\tlearn: 0.4723509\ttotal: 2m 41s\tremaining: 1m 15s\n",
      "341:\tlearn: 0.4719682\ttotal: 2m 42s\tremaining: 1m 15s\n",
      "342:\tlearn: 0.4714327\ttotal: 2m 42s\tremaining: 1m 14s\n",
      "343:\tlearn: 0.4711668\ttotal: 2m 43s\tremaining: 1m 14s\n",
      "344:\tlearn: 0.4706571\ttotal: 2m 44s\tremaining: 1m 13s\n",
      "345:\tlearn: 0.4702061\ttotal: 2m 44s\tremaining: 1m 13s\n",
      "346:\tlearn: 0.4699418\ttotal: 2m 45s\tremaining: 1m 12s\n",
      "347:\tlearn: 0.4697343\ttotal: 2m 45s\tremaining: 1m 12s\n",
      "348:\tlearn: 0.4694567\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "349:\tlearn: 0.4688875\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "350:\tlearn: 0.4684597\ttotal: 2m 47s\tremaining: 1m 11s\n",
      "351:\tlearn: 0.4679857\ttotal: 2m 47s\tremaining: 1m 10s\n",
      "352:\tlearn: 0.4675941\ttotal: 2m 48s\tremaining: 1m 10s\n",
      "353:\tlearn: 0.4672703\ttotal: 2m 49s\tremaining: 1m 9s\n",
      "354:\tlearn: 0.4669845\ttotal: 2m 49s\tremaining: 1m 9s\n",
      "355:\tlearn: 0.4664428\ttotal: 2m 50s\tremaining: 1m 8s\n",
      "356:\tlearn: 0.4660056\ttotal: 2m 50s\tremaining: 1m 8s\n",
      "357:\tlearn: 0.4658102\ttotal: 2m 50s\tremaining: 1m 7s\n",
      "358:\tlearn: 0.4653533\ttotal: 2m 51s\tremaining: 1m 7s\n",
      "359:\tlearn: 0.4649718\ttotal: 2m 51s\tremaining: 1m 6s\n",
      "360:\tlearn: 0.4644122\ttotal: 2m 52s\tremaining: 1m 6s\n",
      "361:\tlearn: 0.4638041\ttotal: 2m 53s\tremaining: 1m 5s\n",
      "362:\tlearn: 0.4632659\ttotal: 2m 53s\tremaining: 1m 5s\n",
      "363:\tlearn: 0.4629563\ttotal: 2m 54s\tremaining: 1m 5s\n",
      "364:\tlearn: 0.4624509\ttotal: 2m 54s\tremaining: 1m 4s\n",
      "365:\tlearn: 0.4622334\ttotal: 2m 55s\tremaining: 1m 4s\n",
      "366:\tlearn: 0.4618518\ttotal: 2m 55s\tremaining: 1m 3s\n",
      "367:\tlearn: 0.4615617\ttotal: 2m 56s\tremaining: 1m 3s\n",
      "368:\tlearn: 0.4612196\ttotal: 2m 56s\tremaining: 1m 2s\n",
      "369:\tlearn: 0.4608171\ttotal: 2m 57s\tremaining: 1m 2s\n",
      "370:\tlearn: 0.4602919\ttotal: 2m 57s\tremaining: 1m 1s\n",
      "371:\tlearn: 0.4599109\ttotal: 2m 57s\tremaining: 1m 1s\n",
      "372:\tlearn: 0.4595718\ttotal: 2m 58s\tremaining: 1m\n",
      "373:\tlearn: 0.4590893\ttotal: 2m 59s\tremaining: 1m\n",
      "374:\tlearn: 0.4586301\ttotal: 2m 59s\tremaining: 59.8s\n",
      "375:\tlearn: 0.4582878\ttotal: 3m\tremaining: 59.4s\n",
      "376:\tlearn: 0.4580101\ttotal: 3m\tremaining: 58.9s\n",
      "377:\tlearn: 0.4577138\ttotal: 3m 1s\tremaining: 58.4s\n",
      "378:\tlearn: 0.4571591\ttotal: 3m 1s\tremaining: 58s\n",
      "379:\tlearn: 0.4567941\ttotal: 3m 2s\tremaining: 57.5s\n",
      "380:\tlearn: 0.4561871\ttotal: 3m 2s\tremaining: 57s\n",
      "381:\tlearn: 0.4558889\ttotal: 3m 3s\tremaining: 56.6s\n",
      "382:\tlearn: 0.4555140\ttotal: 3m 3s\tremaining: 56.1s\n",
      "383:\tlearn: 0.4551898\ttotal: 3m 4s\tremaining: 55.7s\n",
      "384:\tlearn: 0.4547841\ttotal: 3m 4s\tremaining: 55.2s\n",
      "385:\tlearn: 0.4541879\ttotal: 3m 5s\tremaining: 54.7s\n",
      "386:\tlearn: 0.4537766\ttotal: 3m 5s\tremaining: 54.3s\n",
      "387:\tlearn: 0.4534950\ttotal: 3m 6s\tremaining: 53.8s\n",
      "388:\tlearn: 0.4532386\ttotal: 3m 6s\tremaining: 53.3s\n",
      "389:\tlearn: 0.4527849\ttotal: 3m 7s\tremaining: 52.8s\n",
      "390:\tlearn: 0.4524400\ttotal: 3m 7s\tremaining: 52.4s\n",
      "391:\tlearn: 0.4520966\ttotal: 3m 8s\tremaining: 51.9s\n",
      "392:\tlearn: 0.4518329\ttotal: 3m 8s\tremaining: 51.4s\n",
      "393:\tlearn: 0.4513027\ttotal: 3m 9s\tremaining: 50.9s\n",
      "394:\tlearn: 0.4508984\ttotal: 3m 9s\tremaining: 50.5s\n",
      "395:\tlearn: 0.4504634\ttotal: 3m 10s\tremaining: 50s\n",
      "396:\tlearn: 0.4500446\ttotal: 3m 10s\tremaining: 49.5s\n",
      "397:\tlearn: 0.4495779\ttotal: 3m 11s\tremaining: 49s\n",
      "398:\tlearn: 0.4490228\ttotal: 3m 11s\tremaining: 48.5s\n",
      "399:\tlearn: 0.4485203\ttotal: 3m 12s\tremaining: 48.1s\n",
      "400:\tlearn: 0.4480242\ttotal: 3m 12s\tremaining: 47.6s\n",
      "401:\tlearn: 0.4474815\ttotal: 3m 13s\tremaining: 47.1s\n",
      "402:\tlearn: 0.4472110\ttotal: 3m 13s\tremaining: 46.7s\n",
      "403:\tlearn: 0.4464879\ttotal: 3m 14s\tremaining: 46.2s\n",
      "404:\tlearn: 0.4462335\ttotal: 3m 14s\tremaining: 45.7s\n",
      "405:\tlearn: 0.4459767\ttotal: 3m 15s\tremaining: 45.3s\n",
      "406:\tlearn: 0.4457135\ttotal: 3m 16s\tremaining: 44.8s\n",
      "407:\tlearn: 0.4452879\ttotal: 3m 16s\tremaining: 44.3s\n",
      "408:\tlearn: 0.4448758\ttotal: 3m 17s\tremaining: 43.9s\n",
      "409:\tlearn: 0.4445999\ttotal: 3m 17s\tremaining: 43.4s\n",
      "410:\tlearn: 0.4440178\ttotal: 3m 18s\tremaining: 42.9s\n",
      "411:\tlearn: 0.4434910\ttotal: 3m 18s\tremaining: 42.5s\n",
      "412:\tlearn: 0.4432776\ttotal: 3m 19s\tremaining: 42s\n",
      "413:\tlearn: 0.4429822\ttotal: 3m 19s\tremaining: 41.5s\n",
      "414:\tlearn: 0.4422683\ttotal: 3m 20s\tremaining: 41s\n",
      "415:\tlearn: 0.4417174\ttotal: 3m 20s\tremaining: 40.5s\n",
      "416:\tlearn: 0.4412060\ttotal: 3m 21s\tremaining: 40s\n",
      "417:\tlearn: 0.4406341\ttotal: 3m 21s\tremaining: 39.6s\n",
      "418:\tlearn: 0.4403032\ttotal: 3m 22s\tremaining: 39.1s\n",
      "419:\tlearn: 0.4398036\ttotal: 3m 22s\tremaining: 38.6s\n",
      "420:\tlearn: 0.4395164\ttotal: 3m 23s\tremaining: 38.1s\n",
      "421:\tlearn: 0.4391788\ttotal: 3m 23s\tremaining: 37.7s\n",
      "422:\tlearn: 0.4388655\ttotal: 3m 24s\tremaining: 37.2s\n",
      "423:\tlearn: 0.4384401\ttotal: 3m 24s\tremaining: 36.7s\n",
      "424:\tlearn: 0.4379490\ttotal: 3m 25s\tremaining: 36.2s\n",
      "425:\tlearn: 0.4374975\ttotal: 3m 25s\tremaining: 35.7s\n",
      "426:\tlearn: 0.4370993\ttotal: 3m 26s\tremaining: 35.3s\n",
      "427:\tlearn: 0.4366770\ttotal: 3m 26s\tremaining: 34.8s\n",
      "428:\tlearn: 0.4362359\ttotal: 3m 27s\tremaining: 34.3s\n",
      "429:\tlearn: 0.4359550\ttotal: 3m 27s\tremaining: 33.8s\n",
      "430:\tlearn: 0.4355357\ttotal: 3m 28s\tremaining: 33.3s\n",
      "431:\tlearn: 0.4352163\ttotal: 3m 28s\tremaining: 32.9s\n",
      "432:\tlearn: 0.4346393\ttotal: 3m 29s\tremaining: 32.4s\n",
      "433:\tlearn: 0.4343594\ttotal: 3m 29s\tremaining: 31.9s\n",
      "434:\tlearn: 0.4341792\ttotal: 3m 30s\tremaining: 31.4s\n",
      "435:\tlearn: 0.4337363\ttotal: 3m 30s\tremaining: 31s\n",
      "436:\tlearn: 0.4333095\ttotal: 3m 31s\tremaining: 30.5s\n",
      "437:\tlearn: 0.4330311\ttotal: 3m 32s\tremaining: 30s\n",
      "438:\tlearn: 0.4325262\ttotal: 3m 32s\tremaining: 29.5s\n",
      "439:\tlearn: 0.4324324\ttotal: 3m 32s\tremaining: 29s\n",
      "440:\tlearn: 0.4319876\ttotal: 3m 33s\tremaining: 28.6s\n",
      "441:\tlearn: 0.4317521\ttotal: 3m 33s\tremaining: 28.1s\n",
      "442:\tlearn: 0.4313956\ttotal: 3m 34s\tremaining: 27.6s\n",
      "443:\tlearn: 0.4312895\ttotal: 3m 34s\tremaining: 27.1s\n",
      "444:\tlearn: 0.4308673\ttotal: 3m 35s\tremaining: 26.6s\n",
      "445:\tlearn: 0.4303122\ttotal: 3m 35s\tremaining: 26.1s\n",
      "446:\tlearn: 0.4299750\ttotal: 3m 36s\tremaining: 25.6s\n",
      "447:\tlearn: 0.4296089\ttotal: 3m 36s\tremaining: 25.2s\n",
      "448:\tlearn: 0.4293873\ttotal: 3m 37s\tremaining: 24.7s\n",
      "449:\tlearn: 0.4290734\ttotal: 3m 37s\tremaining: 24.2s\n",
      "450:\tlearn: 0.4287380\ttotal: 3m 38s\tremaining: 23.7s\n",
      "451:\tlearn: 0.4280549\ttotal: 3m 39s\tremaining: 23.3s\n",
      "452:\tlearn: 0.4276573\ttotal: 3m 39s\tremaining: 22.8s\n",
      "453:\tlearn: 0.4272414\ttotal: 3m 40s\tremaining: 22.3s\n",
      "454:\tlearn: 0.4269226\ttotal: 3m 40s\tremaining: 21.8s\n",
      "455:\tlearn: 0.4267386\ttotal: 3m 41s\tremaining: 21.4s\n",
      "456:\tlearn: 0.4264952\ttotal: 3m 41s\tremaining: 20.9s\n",
      "457:\tlearn: 0.4261745\ttotal: 3m 42s\tremaining: 20.4s\n",
      "458:\tlearn: 0.4256540\ttotal: 3m 43s\tremaining: 19.9s\n",
      "459:\tlearn: 0.4252262\ttotal: 3m 43s\tremaining: 19.4s\n",
      "460:\tlearn: 0.4248465\ttotal: 3m 44s\tremaining: 19s\n",
      "461:\tlearn: 0.4246818\ttotal: 3m 44s\tremaining: 18.5s\n",
      "462:\tlearn: 0.4241417\ttotal: 3m 45s\tremaining: 18s\n",
      "463:\tlearn: 0.4235672\ttotal: 3m 45s\tremaining: 17.5s\n",
      "464:\tlearn: 0.4230300\ttotal: 3m 46s\tremaining: 17s\n",
      "465:\tlearn: 0.4227744\ttotal: 3m 47s\tremaining: 16.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466:\tlearn: 0.4226454\ttotal: 3m 47s\tremaining: 16.1s\n",
      "467:\tlearn: 0.4222525\ttotal: 3m 48s\tremaining: 15.6s\n",
      "468:\tlearn: 0.4219332\ttotal: 3m 49s\tremaining: 15.1s\n",
      "469:\tlearn: 0.4214404\ttotal: 3m 49s\tremaining: 14.7s\n",
      "470:\tlearn: 0.4210953\ttotal: 3m 50s\tremaining: 14.2s\n",
      "471:\tlearn: 0.4207631\ttotal: 3m 50s\tremaining: 13.7s\n",
      "472:\tlearn: 0.4202719\ttotal: 3m 51s\tremaining: 13.2s\n",
      "473:\tlearn: 0.4200551\ttotal: 3m 51s\tremaining: 12.7s\n",
      "474:\tlearn: 0.4196316\ttotal: 3m 52s\tremaining: 12.2s\n",
      "475:\tlearn: 0.4193843\ttotal: 3m 52s\tremaining: 11.7s\n",
      "476:\tlearn: 0.4189667\ttotal: 3m 53s\tremaining: 11.3s\n",
      "477:\tlearn: 0.4185810\ttotal: 3m 53s\tremaining: 10.8s\n",
      "478:\tlearn: 0.4181833\ttotal: 3m 54s\tremaining: 10.3s\n",
      "479:\tlearn: 0.4177480\ttotal: 3m 54s\tremaining: 9.79s\n",
      "480:\tlearn: 0.4172525\ttotal: 3m 55s\tremaining: 9.3s\n",
      "481:\tlearn: 0.4165552\ttotal: 3m 55s\tremaining: 8.81s\n",
      "482:\tlearn: 0.4159659\ttotal: 3m 56s\tremaining: 8.32s\n",
      "483:\tlearn: 0.4156252\ttotal: 3m 57s\tremaining: 7.84s\n",
      "484:\tlearn: 0.4154230\ttotal: 3m 57s\tremaining: 7.35s\n",
      "485:\tlearn: 0.4151269\ttotal: 3m 58s\tremaining: 6.86s\n",
      "486:\tlearn: 0.4148287\ttotal: 3m 58s\tremaining: 6.38s\n",
      "487:\tlearn: 0.4143050\ttotal: 3m 59s\tremaining: 5.89s\n",
      "488:\tlearn: 0.4140351\ttotal: 3m 59s\tremaining: 5.4s\n",
      "489:\tlearn: 0.4136439\ttotal: 4m\tremaining: 4.91s\n",
      "490:\tlearn: 0.4132759\ttotal: 4m\tremaining: 4.42s\n",
      "491:\tlearn: 0.4129684\ttotal: 4m 1s\tremaining: 3.93s\n",
      "492:\tlearn: 0.4125640\ttotal: 4m 2s\tremaining: 3.44s\n",
      "493:\tlearn: 0.4122809\ttotal: 4m 2s\tremaining: 2.94s\n",
      "494:\tlearn: 0.4119129\ttotal: 4m 2s\tremaining: 2.45s\n",
      "495:\tlearn: 0.4116470\ttotal: 4m 3s\tremaining: 1.96s\n",
      "496:\tlearn: 0.4114851\ttotal: 4m 4s\tremaining: 1.47s\n",
      "497:\tlearn: 0.4110065\ttotal: 4m 4s\tremaining: 982ms\n",
      "498:\tlearn: 0.4106751\ttotal: 4m 5s\tremaining: 491ms\n",
      "499:\tlearn: 0.4102798\ttotal: 4m 5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x281ae940eb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoostClassifier 생성\n",
    "model = CatBoostClassifier(iterations=500,\n",
    "                           depth=10,\n",
    "                           learning_rate=0.05,\n",
    "                           loss_function='MultiClass',\n",
    "                           cat_features=category_columns,\n",
    "                           random_state=42)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57dec6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7140099282956426\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "accuracy = model.score(X_test1, y_test1)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f4458e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "098c9c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "983670b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3303  864    0]\n",
      " [ 966 1845   23]\n",
      " [  26  195   30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test1, guesses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1819473",
   "metadata": {},
   "source": [
    "#### 3.5 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c585c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    activation = trial.suggest_categorical('activation', ['relu','logistic'])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True)\n",
    "\n",
    "    # MLP 모델 생성\n",
    "    model = MLPClassifier(hidden_layer_sizes=(32,16,8),\n",
    "                          max_iter=500,\n",
    "                          activation=activation,\n",
    "                          learning_rate_init=learning_rate,\n",
    "                          solver='adam',\n",
    "                          random_state=42)\n",
    "\n",
    "    \n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 검증 데이터에 대한 평가 지표 계산\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "589b348c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 02:15:39,027] A new study created in memory with name: no-name-859a430b-0511-42e7-b6d3-7d14831d4b5e\n",
      "[I 2023-11-24 02:16:00,961] Trial 0 finished with value: 0.6861555432984004 and parameters: {'activation': 'relu', 'learning_rate': 0.00302511008404565}. Best is trial 0 with value: 0.6861555432984004.\n",
      "[I 2023-11-24 02:16:19,494] Trial 1 finished with value: 0.6858797573083287 and parameters: {'activation': 'relu', 'learning_rate': 0.0018641766752840966}. Best is trial 0 with value: 0.6861555432984004.\n",
      "[I 2023-11-24 02:16:32,611] Trial 2 finished with value: 0.6817429674572532 and parameters: {'activation': 'logistic', 'learning_rate': 0.030921723848931857}. Best is trial 0 with value: 0.6861555432984004.\n",
      "[I 2023-11-24 02:16:46,321] Trial 3 finished with value: 0.6829840044125759 and parameters: {'activation': 'logistic', 'learning_rate': 0.019084550713975714}. Best is trial 0 with value: 0.6861555432984004.\n",
      "[I 2023-11-24 02:17:10,160] Trial 4 finished with value: 0.6897407611693326 and parameters: {'activation': 'relu', 'learning_rate': 0.003696443368804985}. Best is trial 4 with value: 0.6897407611693326.\n",
      "[I 2023-11-24 02:17:18,966] Trial 5 finished with value: 0.6589906232763376 and parameters: {'activation': 'relu', 'learning_rate': 0.051783954142062424}. Best is trial 4 with value: 0.6897407611693326.\n",
      "[I 2023-11-24 02:17:51,585] Trial 6 finished with value: 0.6869829012686156 and parameters: {'activation': 'logistic', 'learning_rate': 0.0023058259573109315}. Best is trial 4 with value: 0.6897407611693326.\n",
      "[I 2023-11-24 02:17:54,021] Trial 7 finished with value: 0.5746001103143961 and parameters: {'activation': 'relu', 'learning_rate': 0.0976035164854384}. Best is trial 4 with value: 0.6897407611693326.\n",
      "[I 2023-11-24 02:18:14,270] Trial 8 finished with value: 0.6809156094870381 and parameters: {'activation': 'relu', 'learning_rate': 0.002379240645185304}. Best is trial 4 with value: 0.6897407611693326.\n",
      "[I 2023-11-24 02:18:17,449] Trial 9 finished with value: 0.6224489795918368 and parameters: {'activation': 'relu', 'learning_rate': 0.08169819118031707}. Best is trial 4 with value: 0.6897407611693326.\n",
      "[I 2023-11-24 02:18:47,352] Trial 10 finished with value: 0.6898786541643684 and parameters: {'activation': 'logistic', 'learning_rate': 0.007478696991789755}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:19:17,427] Trial 11 finished with value: 0.6898786541643684 and parameters: {'activation': 'logistic', 'learning_rate': 0.00600035671634396}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:19:44,257] Trial 12 finished with value: 0.6868450082735797 and parameters: {'activation': 'logistic', 'learning_rate': 0.007328413446579264}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:20:10,860] Trial 13 finished with value: 0.6858797573083287 and parameters: {'activation': 'logistic', 'learning_rate': 0.007318165263144314}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:20:42,671] Trial 14 finished with value: 0.6778819635962493 and parameters: {'activation': 'logistic', 'learning_rate': 0.0010649879017995232}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:21:08,355] Trial 15 finished with value: 0.6805019305019305 and parameters: {'activation': 'logistic', 'learning_rate': 0.012157001021338569}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:21:43,137] Trial 16 finished with value: 0.6887755102040817 and parameters: {'activation': 'logistic', 'learning_rate': 0.004883865115269568}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:22:02,516] Trial 17 finished with value: 0.6858797573083287 and parameters: {'activation': 'logistic', 'learning_rate': 0.013370692287467496}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:22:34,851] Trial 18 finished with value: 0.6780198565912852 and parameters: {'activation': 'logistic', 'learning_rate': 0.007202622781613588}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:22:51,687] Trial 19 finished with value: 0.6878102592388307 and parameters: {'activation': 'logistic', 'learning_rate': 0.018032797471216454}. Best is trial 10 with value: 0.6898786541643684.\n",
      "[I 2023-11-24 02:23:20,513] Trial 20 finished with value: 0.6934638720353006 and parameters: {'activation': 'logistic', 'learning_rate': 0.004903017211572883}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:23:52,010] Trial 21 finished with value: 0.686569222283508 and parameters: {'activation': 'logistic', 'learning_rate': 0.0047155665342484025}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:24:24,007] Trial 22 finished with value: 0.6880860452289024 and parameters: {'activation': 'logistic', 'learning_rate': 0.005667434551490518}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:24:48,791] Trial 23 finished with value: 0.6907060121345836 and parameters: {'activation': 'logistic', 'learning_rate': 0.009508216952674101}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:25:16,083] Trial 24 finished with value: 0.6840871483728627 and parameters: {'activation': 'logistic', 'learning_rate': 0.009532464324949702}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:25:51,475] Trial 25 finished with value: 0.6829840044125759 and parameters: {'activation': 'logistic', 'learning_rate': 0.010046820426639853}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:26:25,576] Trial 26 finished with value: 0.6883618312189741 and parameters: {'activation': 'logistic', 'learning_rate': 0.003797622877533551}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:26:43,594] Trial 27 finished with value: 0.6799503585217871 and parameters: {'activation': 'logistic', 'learning_rate': 0.015017530082525366}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:27:15,353] Trial 28 finished with value: 0.6909817981246553 and parameters: {'activation': 'logistic', 'learning_rate': 0.009340522673675184}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:27:49,240] Trial 29 finished with value: 0.6889134031991175 and parameters: {'activation': 'logistic', 'learning_rate': 0.009994622946870122}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:28:02,084] Trial 30 finished with value: 0.6838113623827909 and parameters: {'activation': 'logistic', 'learning_rate': 0.024315664269761388}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:28:28,719] Trial 31 finished with value: 0.6918091560948704 and parameters: {'activation': 'logistic', 'learning_rate': 0.008616164609087318}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:28:54,807] Trial 32 finished with value: 0.6860176503033646 and parameters: {'activation': 'logistic', 'learning_rate': 0.01073740223607251}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:29:27,656] Trial 33 finished with value: 0.6920849420849421 and parameters: {'activation': 'logistic', 'learning_rate': 0.0033601011466141955}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:30:01,379] Trial 34 finished with value: 0.68849972421401 and parameters: {'activation': 'logistic', 'learning_rate': 0.003795392234020922}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:30:13,676] Trial 35 finished with value: 0.6897407611693326 and parameters: {'activation': 'relu', 'learning_rate': 0.002948158423658672}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:30:46,188] Trial 36 finished with value: 0.6891891891891891 and parameters: {'activation': 'logistic', 'learning_rate': 0.00463966831230726}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:31:33,929] Trial 37 finished with value: 0.6919470490899062 and parameters: {'activation': 'logistic', 'learning_rate': 0.003128725223010042}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:32:09,372] Trial 38 finished with value: 0.6868450082735797 and parameters: {'activation': 'relu', 'learning_rate': 0.0016428672693075683}. Best is trial 20 with value: 0.6934638720353006.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 02:32:42,682] Trial 39 finished with value: 0.6898786541643684 and parameters: {'activation': 'logistic', 'learning_rate': 0.0029632572044093887}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:33:10,839] Trial 40 finished with value: 0.6875344732487589 and parameters: {'activation': 'relu', 'learning_rate': 0.0022611544095083036}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:34:00,628] Trial 41 finished with value: 0.6920849420849421 and parameters: {'activation': 'logistic', 'learning_rate': 0.0036855149295595196}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:34:35,690] Trial 42 finished with value: 0.6883618312189741 and parameters: {'activation': 'logistic', 'learning_rate': 0.003464420183252045}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:35:07,656] Trial 43 finished with value: 0.6913954771097628 and parameters: {'activation': 'logistic', 'learning_rate': 0.004274518548967719}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:35:38,003] Trial 44 finished with value: 0.68849972421401 and parameters: {'activation': 'logistic', 'learning_rate': 0.005685298614308397}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:36:08,436] Trial 45 finished with value: 0.6915333701047987 and parameters: {'activation': 'logistic', 'learning_rate': 0.002955739660227179}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:36:38,589] Trial 46 finished with value: 0.6796745725317154 and parameters: {'activation': 'relu', 'learning_rate': 0.0024768673076283605}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:37:25,578] Trial 47 finished with value: 0.6904302261445119 and parameters: {'activation': 'logistic', 'learning_rate': 0.0035326190731098713}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:37:56,508] Trial 48 finished with value: 0.6909817981246553 and parameters: {'activation': 'logistic', 'learning_rate': 0.005859005484967759}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:38:41,829] Trial 49 finished with value: 0.6829840044125759 and parameters: {'activation': 'logistic', 'learning_rate': 0.0018758280525003849}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:39:13,020] Trial 50 finished with value: 0.6889134031991175 and parameters: {'activation': 'logistic', 'learning_rate': 0.004338450558771421}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:39:43,532] Trial 51 finished with value: 0.6882239382239382 and parameters: {'activation': 'logistic', 'learning_rate': 0.0030010659763715333}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:40:16,429] Trial 52 finished with value: 0.6867071152785439 and parameters: {'activation': 'logistic', 'learning_rate': 0.002764314614404099}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:40:46,907] Trial 53 finished with value: 0.6919470490899062 and parameters: {'activation': 'logistic', 'learning_rate': 0.0032995869422101703}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:41:13,133] Trial 54 finished with value: 0.6894649751792609 and parameters: {'activation': 'logistic', 'learning_rate': 0.004974722634615446}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:41:43,415] Trial 55 finished with value: 0.6897407611693326 and parameters: {'activation': 'logistic', 'learning_rate': 0.006664295748582714}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:42:30,429] Trial 56 finished with value: 0.6907060121345836 and parameters: {'activation': 'logistic', 'learning_rate': 0.0035361092674878435}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:42:43,489] Trial 57 finished with value: 0.6817429674572532 and parameters: {'activation': 'relu', 'learning_rate': 0.005029633747680232}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:43:10,920] Trial 58 finished with value: 0.6867071152785439 and parameters: {'activation': 'logistic', 'learning_rate': 0.008132427017472925}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:43:41,825] Trial 59 finished with value: 0.690292333149476 and parameters: {'activation': 'logistic', 'learning_rate': 0.006706518891087444}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:44:14,795] Trial 60 finished with value: 0.686569222283508 and parameters: {'activation': 'logistic', 'learning_rate': 0.004087272255189643}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:44:59,732] Trial 61 finished with value: 0.6907060121345836 and parameters: {'activation': 'logistic', 'learning_rate': 0.0036021785203926245}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:45:30,938] Trial 62 finished with value: 0.6858797573083287 and parameters: {'activation': 'logistic', 'learning_rate': 0.002514041988612759}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:46:03,463] Trial 63 finished with value: 0.6820187534473249 and parameters: {'activation': 'logistic', 'learning_rate': 0.00521260188978908}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:46:34,498] Trial 64 finished with value: 0.6909817981246553 and parameters: {'activation': 'logistic', 'learning_rate': 0.003288875852684372}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:47:05,943] Trial 65 finished with value: 0.6909817981246553 and parameters: {'activation': 'logistic', 'learning_rate': 0.0042900593759631934}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:47:36,829] Trial 66 finished with value: 0.684776613348042 and parameters: {'activation': 'logistic', 'learning_rate': 0.002108734688289413}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:48:07,478] Trial 67 finished with value: 0.689327082184225 and parameters: {'activation': 'logistic', 'learning_rate': 0.002680051967194649}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:48:40,464] Trial 68 finished with value: 0.6864313292884722 and parameters: {'activation': 'logistic', 'learning_rate': 0.004022908561602379}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:49:10,862] Trial 69 finished with value: 0.692222835079978 and parameters: {'activation': 'logistic', 'learning_rate': 0.0033073951973650083}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:49:30,857] Trial 70 finished with value: 0.6850523993381136 and parameters: {'activation': 'relu', 'learning_rate': 0.005252701801037926}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:50:15,275] Trial 71 finished with value: 0.6923607280750138 and parameters: {'activation': 'logistic', 'learning_rate': 0.0031124417351546148}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:50:45,824] Trial 72 finished with value: 0.6915333701047987 and parameters: {'activation': 'logistic', 'learning_rate': 0.004461305651623592}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:51:17,419] Trial 73 finished with value: 0.6908439051296195 and parameters: {'activation': 'logistic', 'learning_rate': 0.003353477315547178}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:51:47,727] Trial 74 finished with value: 0.692222835079978 and parameters: {'activation': 'logistic', 'learning_rate': 0.0032689422686733843}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:52:18,516] Trial 75 finished with value: 0.6894649751792609 and parameters: {'activation': 'logistic', 'learning_rate': 0.0026180292048742157}. Best is trial 20 with value: 0.6934638720353006.\n",
      "C:\\Users\\gksxk\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2023-11-24 02:53:06,449] Trial 76 finished with value: 0.6907060121345836 and parameters: {'activation': 'logistic', 'learning_rate': 0.00311852616838595}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:53:37,567] Trial 77 finished with value: 0.6846387203530061 and parameters: {'activation': 'logistic', 'learning_rate': 0.0021166886588334286}. Best is trial 20 with value: 0.6934638720353006.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-24 02:54:19,659] Trial 78 finished with value: 0.6908439051296195 and parameters: {'activation': 'logistic', 'learning_rate': 0.0037474768793824744}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:54:52,526] Trial 79 finished with value: 0.6879481522338665 and parameters: {'activation': 'logistic', 'learning_rate': 0.0031500837820273232}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:55:24,027] Trial 80 finished with value: 0.6879481522338665 and parameters: {'activation': 'logistic', 'learning_rate': 0.00233612485235511}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:55:55,709] Trial 81 finished with value: 0.686569222283508 and parameters: {'activation': 'logistic', 'learning_rate': 0.0027952433785647206}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:56:28,272] Trial 82 finished with value: 0.6889134031991175 and parameters: {'activation': 'logistic', 'learning_rate': 0.0037804129503424106}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:56:58,319] Trial 83 finished with value: 0.6889134031991175 and parameters: {'activation': 'logistic', 'learning_rate': 0.004675670393308226}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:57:28,441] Trial 84 finished with value: 0.6913954771097628 and parameters: {'activation': 'logistic', 'learning_rate': 0.0032817161902707398}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:57:58,812] Trial 85 finished with value: 0.6907060121345836 and parameters: {'activation': 'logistic', 'learning_rate': 0.006089627153314102}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:58:29,106] Trial 86 finished with value: 0.68849972421401 and parameters: {'activation': 'logistic', 'learning_rate': 0.002663852135146446}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:58:44,830] Trial 87 finished with value: 0.6843629343629344 and parameters: {'activation': 'relu', 'learning_rate': 0.0037946431556096735}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:59:19,389] Trial 88 finished with value: 0.6864313292884722 and parameters: {'activation': 'logistic', 'learning_rate': 0.004098004090759228}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 02:59:46,007] Trial 89 finished with value: 0.6905681191395477 and parameters: {'activation': 'logistic', 'learning_rate': 0.005508306606992622}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:00:18,356] Trial 90 finished with value: 0.6846387203530061 and parameters: {'activation': 'logistic', 'learning_rate': 0.00469860619171886}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:00:49,138] Trial 91 finished with value: 0.6891891891891891 and parameters: {'activation': 'logistic', 'learning_rate': 0.002981913991391608}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:01:19,541] Trial 92 finished with value: 0.6897407611693326 and parameters: {'activation': 'logistic', 'learning_rate': 0.002973044562180112}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:01:49,791] Trial 93 finished with value: 0.6909817981246553 and parameters: {'activation': 'logistic', 'learning_rate': 0.0033821264362933383}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:02:19,424] Trial 94 finished with value: 0.6846387203530061 and parameters: {'activation': 'logistic', 'learning_rate': 0.0025403962306662638}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:02:52,126] Trial 95 finished with value: 0.6913954771097628 and parameters: {'activation': 'logistic', 'learning_rate': 0.0041483090890838}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:03:22,691] Trial 96 finished with value: 0.6858797573083287 and parameters: {'activation': 'logistic', 'learning_rate': 0.00229799166729066}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:03:52,605] Trial 97 finished with value: 0.6909817981246553 and parameters: {'activation': 'logistic', 'learning_rate': 0.0028955424770952536}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:04:40,692] Trial 98 finished with value: 0.6890512961941533 and parameters: {'activation': 'logistic', 'learning_rate': 0.0035484714958072447}. Best is trial 20 with value: 0.6934638720353006.\n",
      "[I 2023-11-24 03:04:51,856] Trial 99 finished with value: 0.6876723662437948 and parameters: {'activation': 'relu', 'learning_rate': 0.003190497937084051}. Best is trial 20 with value: 0.6934638720353006.\n"
     ]
    }
   ],
   "source": [
    "# Optuna로 하이퍼파라미터 최적화 수행\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27ce87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'activation': 'logistic', 'learning_rate': 0.004903017211572883}\n",
      "Best Accuracy: 0.6934638720353006\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터 및 결과 출력\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72868c1",
   "metadata": {},
   "source": [
    "#### 3.6 Stacking( 조정된 최적의 파라미터를 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3688b1",
   "metadata": {},
   "source": [
    "decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d597f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=133,\n",
    "        max_depth=20,\n",
    "        min_samples_split=17,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42)),\n",
    "    ('ada', AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=4),\n",
    "        n_estimators=175,\n",
    "        learning_rate=0.15900320437580656,\n",
    "        random_state=42)),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(32,16,8),\n",
    "                          max_iter=500,\n",
    "                          activation='logistic',\n",
    "                          learning_rate_init=0.004903017211572883,\n",
    "                          solver='adam',\n",
    "                          random_state=42))\n",
    "]\n",
    "classifier = StackingClassifier(estimators=base_models, \n",
    "                                final_estimator=DecisionTreeClassifier())\n",
    "classifier.fit(X_train, y_train)\n",
    "stack_guesses = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f313cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6169332597904027\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, stack_guesses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90387dc",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f5da0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=133,\n",
    "        max_depth=20,\n",
    "        min_samples_split=17,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42)),\n",
    "    ('ada', AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=4),\n",
    "        n_estimators=175,\n",
    "        learning_rate=0.15900320437580656,\n",
    "        random_state=42)),\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes=(32,16,8),\n",
    "                          max_iter=500,\n",
    "                          activation='logistic',\n",
    "                          learning_rate_init=0.004903017211572883,\n",
    "                          solver='adam',\n",
    "                          random_state=42))\n",
    "]\n",
    "classifier = StackingClassifier(estimators=base_models, \n",
    "                                final_estimator=LogisticRegression(max_iter=1000))\n",
    "classifier.fit(X_train, y_train)\n",
    "stack_guesses = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caa45b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.706150027578599\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, stack_guesses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
